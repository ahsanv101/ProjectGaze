{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Through the Gaze - Data documentation\n",
    "This Jupyter Notebook analyses the data preparation and processing phase for [\"NameProject\"](https://ahsanv101.github.io/ProjectGaze/).\n",
    "\n",
    "For this project, we are interested in studying the concept of the **\"male gaze\"** in cinema, inspired by the essay \"Visual Pleasure and Narrative Cinema\" by the feminist film theorist Laura Mulvey. Mulvey underlines how the \"male gaze\" is made of three main components:\n",
    "1. The audience\n",
    "2. The characters\n",
    "3. The camera (i.e. the director)\n",
    "\n",
    "To represent a coherent and significant overview on the male gaze's impact on western cinematic industry, we will identify the **10 highest-grossing U.S. films for each decade from 1940s to 2010s**. The reason to opt for highest-grossing movies is that they give a general understanding of the popularity of the movie also in terms of fame and profit (highest grossing = surplus amount of people saw it), as well as produce a sort of cultural normativity.\n",
    "Taking highest-grossing movies per decade will help us generalize our results in terms of popularity.\n",
    "\n",
    "\n",
    "### Disclaimer \n",
    "This Jupyter Notebook is of informational nature only, it is not thought to be used for the data preparation and processing, but only for the analysis and explanation of such processes.\n",
    "<br>The Python files used for the clean up can be found in the `code` folder of the [Github repository](https://github.com/ahsanv101/ProjectGaze)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The audience: webscraping, sentiment and sexism\n",
    "Focusing on the audience component of the male gaze implied looking through some of the **reviews** provided for all the movies belonging to our dataset, and focusing not only on the overall reception of the movie, but mostly on the individuals' perception of it and possible gender bias underlying their opinion.\n",
    "\n",
    "\n",
    "Reviews are **not accompanied by the user that provided them**, since that was not useful for our analysis: what is important to keep in mind is that our reviews' dataset comprehends 1972 reviews related to our chosen movies, and that they are completely **public and available on the IMDB's reviews' pages**. Moreover, it's essential to underline that our analysis is partial and neutral, and hopes to elaborate useful reflections more than harsh critiques. \n",
    "\n",
    "### Reviews webscraping\n",
    "The first step of our audience's analysis comprehended a webscraping of the reviews' pages provided in the movie.csv files in URLs form. To do so, we used the [**BeautifulSoup library**](https://www.crummy.com/software/BeautifulSoup/) and we inspected the HTML structure of a standard IMDB's review's page: the textual content of any review is stored inside a `div` block marked by the tag \"text\", and here we access to all of our data. \n",
    "<br>\n",
    "The task, mostly automated, only required a division of the URLS into chunks, to speed up the overall scraping process (since we were working with huge amounts of data!). \n",
    "\n",
    "\n",
    "We later stored our reviews in a dictionary, then turned dataframe, then turned into a **`.csv` file**, containing a unique column, `Reviews`, alongside an index. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#We used the following libraries!\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "#Here we initialize and modify our CSVs accordingly and we create a list for the webscraped reviews \n",
    "movies = pd.read_csv('movies.csv')\n",
    "title_reviews = movies[['Title','Reviews']].copy()\n",
    "\n",
    "text_reviews = []\n",
    "\n",
    "#The webrascraping starts here\n",
    "batch_size = 79\n",
    "urls = ['https://www.imdb.com/title/tt0038969/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0041838/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0031381/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0037536/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0034167/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0036872/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0039391/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0035575/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0034583/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0040806/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0049833/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0045793/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0044672/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0044672/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0047673/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0043949/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0051459/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0053291/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0048593/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0042192/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0059742/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0061722/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0064115/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0058331/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0056937/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0062622/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0055614/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0054215/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0056172/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0060164/?ref_=nv_sr_srsg_3', 'https://www.imdb.com/title/tt0073195/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0076759/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0070047/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0077631/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0068646/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0071230/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0075148/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0066011/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0078346/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0067093/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0080684/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0083866/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0096895/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0086190/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0087332/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0088763/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0092099/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0092644/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0096438/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0081573/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0120338/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0120915/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0107290/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0116629/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0109830/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0119654/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0099653/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0103064/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0103776/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0112462/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0468569/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0383574/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0145487/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0417741/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0121766/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0316654/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0418279/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0325980/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0241527/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0120755/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt4154796/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt1825683/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt2488496/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0848228/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt2527336/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0499549/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0770828/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt3748528/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt1201607/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt1877832/reviews?ref_=tt_urv']\n",
    "url_chunks = [urls[x:x+batch_size] for x in range(0, len(urls), batch_size)]\n",
    "\n",
    "def scrape_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for links in soup.find_all('div', class_='text'):\n",
    "            review = links.get_text()\n",
    "            text_reviews.append(review)\n",
    "def scrape_batch(url_chunk):\n",
    "    chunk_resp = []\n",
    "    for url in url_chunk:\n",
    "        chunk_resp.append(scrape_url(url))\n",
    "    return chunk_resp\n",
    "for url_chunk in url_chunks:\n",
    "    scrape_batch(url_chunk)\n",
    "    \n",
    "#From the list, we store our results into a dictionary, to later convert into a new dataframe and CSV. \n",
    "reviews_dict = {'Reviews': text_reviews}\n",
    "text_reviews = pd.DataFrame.from_dict(reviews_dict)\n",
    "text_reviews.to_csv(\"text_reviews.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "Now that our reviews were available, it was time to actually start working on our analysis: this second step focused mostly on **retrieving the sentiment of our reviews**: *are they positive or negative?*\n",
    "<br>\n",
    "This aspect was later used to understand if there were any strong correlations among the possible sexist tone of a review and its overall sentiment: for example, *how does a poor opinion on women affect the overall perception of a movie?* *Are negative reviews the most sexist?*\n",
    "\n",
    "\n",
    "To achieve a correct sentiment analysis, we used the [**library `NLTK`**](https://www.nltk.org/) and its **`VADER`**, a rule-based sentiment analyzer in which the terms are generally labeled as per their semantic orientation as either positive or negative. \n",
    "The result of this analysis was a **new dataframe** containing our `Reviews` column, a new `Scores` column (containing non-weighted sentiment analysis scores, divided into negative, neutral and positive values), a `Compound` column (weighted values between 0 and 1) and a `Sentiment` column, that provides a clear label distinguishing Positive reviews (pos) from Negative ones (neg). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "df = pd.read_csv('text_reviews.csv')\n",
    "\n",
    "#Here starts the sentiment analysis \n",
    "df.dropna(inplace=True)\n",
    "empty_objects = []\n",
    "for review in df.itertuples():\n",
    "     if type(review)==str:\n",
    "             if review.isspace():\n",
    "                     empty_objects.append(review)\n",
    "df.drop(empty_objects, inplace=True)\n",
    "\n",
    "#We calculate overall scores, compound value and the sentiment label. \n",
    "df['scores'] = df['Reviews'].apply(lambda Reviews: vader.polarity_scores(Reviews))\n",
    "df['compound'] = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df['sentiment'] = df['compound'].apply(lambda c: 'pos' if c >= 0 else 'neg')\n",
    "\n",
    "#... And then we obtain the CSV\n",
    "df.to_csv('sentiment_reviews.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sexism Analysis\n",
    "Having cleared the overall sentiment of our reviews, the final step of our audience's analysis comprehended **detecting possible traces of sexism in the reviews**.\n",
    "<br>\n",
    "To do this, we applied a model created and published by the group NLP-LTU on Hugging Face, the [**BerTweet Large Sexism Detector**](https://huggingface.co/NLP-LTU/bertweet-large-sexism-detector), a classification model for detecting sexism in Tweets or short text paragraphs. As some of our reviews were longer than the model's length limit, a few adjustments were implemented.\n",
    "\n",
    "\n",
    "At the end, we obtained a clear result: our reviews were not sexist or, at least, they were *not completely* sexist.\n",
    "<br>\n",
    "BERT categorized them as lacking any kind of gender bias, but, having inspected the reviews ourselves, we knew this was not true: a few reviews showed clear signs of misogyny and sexism, not just by using offensive words such as \"bitch\" or \"tramp\" when referring to actresses or their characters, but by constantly describing them as sexy and beautiful or by comparing them to animals. \n",
    "BERT simply failed to recognized them because, if considered in a quantified way, those sentences weighted very little in the general structure of the review, that otherwise had a very neutral or even positive tone. \n",
    "What emerged from this analysis, is that **the audience's gaze is rarely guided by pure prejudice or malevolence**: realistically, our reviews displayed sexism in a \"natural\" and subtle way, so subtle that even the sexism-detector model failed to aknowledge them when analysing the bigger picture. \n",
    "\n",
    "However, we were not satisfied with this result: we wanted to isolate these instances of sexism, and to do so, we needed to narrow the detector's scope of analysis. Therefore, we introduced a simpler function capable of dividing any reviews into smaller sentences: by doing this, we could obtain singular scores of sexism and give them more significance. \n",
    "If a review had a singular sexist sentence, was therefore marked as sexist, and sorted into the final CSV accordingly to its final sexist score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this code to work, the libraries Transformers and Torch are needed. \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer,pipeline\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "#We define the model, tokenizer and classifier we are going to use \n",
    "model = AutoModelForSequenceClassification.from_pretrained('NLP-LTU/bertweet-large-sexism-detector')\n",
    "tokenizer = AutoTokenizer.from_pretrained('NLP-LTU/bertweet-large-sexism-detector') \n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "df = pd.read_csv('sentiment_reviews.csv')\n",
    "\n",
    "\n",
    "#This portion of codes generates a prediction of the OVERALL review. According to the tensor size, it proceeds directly with the prediction or it adds an ulterior preprocessing and tokenization phase. \n",
    "import math\n",
    "\n",
    "for item in df['Reviews']: \n",
    "  if (len(item.split())>512):\n",
    "    n=math.ceil(len(item.split())/512)\n",
    "    for i in range(n):\n",
    "        if (i==(n-1)):\n",
    "          safe_item=' '.join(item.split()[i*512::])  \n",
    "        else:\n",
    "          item=' '.join(item.split()[i*512:(i+1)*512])\n",
    "          tokenized = tokenizer.encode(item, padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
    "          prediction = classifier(str(tokenized))\n",
    "          print(prediction, item)\n",
    "          \n",
    "#To work on the individual sentences, we used this instead. \n",
    "\n",
    "reviews = []\n",
    "sentences = []\n",
    "\n",
    "for index, item in df.Reviews.items(): \n",
    "      sentence = item.split('.')      \n",
    "      prediction = classifier(sentence)\n",
    "      sentences.append(sentence)  \n",
    "      reviews.append(prediction)\n",
    "      print([sentence, prediction])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The characters: film and scripts analysis\n",
    "The aim of this analysis is to extract the dominance of the male gaze in the scope of the film and script. This is one of the most important analysis as we also directly dive into the core content of the cinema industry which are the scripts, the basis of any film. The reason we chose scripts is because they address **the whole setting of the characters** as well as **how they are defined on the camera** (viewers) and **how the male character in the script perceives the non-male ones**. They also show what kind of dialogues or actions are assigned to male ones vs non male and give us a good comparative analysis. \n",
    "\n",
    "\n",
    "### Bechdel Test\n",
    "The first step into this analysis is the infamous [Bechdel Test](https://bechdeltest.com/), used for measuring **how women are represented in a given film**. There are generally three rules that a film needs to pass:\n",
    "\n",
    "1. The movie has to have at least two women in it\n",
    "2. The movie has to have at least two women who talk to each other\n",
    "3. The movie has to have at least two women who talk to each other and it is about something other than a man\n",
    "\n",
    "If a movie passes all three of the rules then it passes the Bechdel test. This goes to show a very bare minimum bar that ideally every movie should have. We will collect that data from already existing datasets and check the results with the scope of our movies. \n",
    "\n",
    "> **Graphs**\n",
    "> 1. Passed and not passed: bar chart --> highlights difference\n",
    "> 2. Stacked or donut for not passed, showing 3 layers with dynamic list of the movies\n",
    " \n",
    "\n",
    "### Character Description\n",
    "In this step we will be diving into the **actual descriptions of characters in the scripts**. The idea of using descriptions of the characters is to get an understanding of how the camera wants to show certain features of the characters through the use of angles: in this way the camera becomes the gaze and the (non-male) character becomes the object for the gaze.\n",
    "\n",
    "Our aim is to extract automatically such descriptions from the scripts using Natural Language Processing and show the words which are often used in the describing characters (both male and non-male), revealing the differences in the way they are portayed. We also aim to **categorize female descriptions** in terms of *highly sexist* descriptions and *dubious but problematic* descriptions.\n",
    "\n",
    "> **Graphs**\n",
    "> 1. Overall picture: word cloud: him versus her\n",
    "> 2. Division of descriptions in layers - donut or stacked bar with layers with dynamic list\n",
    "\n",
    "\n",
    "### Character Dialogue\n",
    "In this step we are extracting all the dialogues spoken by male and non-male characters for each script automatically also using NLP tasks. The aim here is to show just how much the **division and representation of words** are given to men vs non-men characters. \n",
    "\n",
    "> **Graphs**\n",
    "> 1. Vertical bar chart showing percentages between men and women\n",
    "\n",
    "### Final \"Gaze Score\"\n",
    "In this step we will be developing a mechanism in order to **assign a score to each film** within our scope. This scoring is important for us as we take into account all the factors analyzed above and assign a score from a **range of 0-100**.\n",
    "\n",
    "The divisiion of the score is as follows:\n",
    "1. **Bechdel Test** (max. 40%), score assigned based on the following criteria\n",
    "    1. If a movie passes **no rule**: 40%\n",
    "    2. If a movie passes **only the first rule**: 26.66%\n",
    "    3. If a movie passes **only the first and second rules**: 13.33%\n",
    "    4. If a movie passes **all rules**: 0%\n",
    "2. **Character description** (max. 35%), score assigned based on the following criteria\n",
    "    1. If a female character is described in a **highly sexist** manner: 35%\n",
    "    2. If a female character is described in a **dubious but problematic** manner: 17.5%\n",
    "    3. If a female character is not described in any of the above manners: 0%\n",
    "3. **Character dialogues** (max. 25%), score assigned based on the following criteria:\n",
    "    1. If a male character has less than or equal to 50% of the overrall dialogue in the script: 0%\n",
    "    2. If a male character has more than or equal to 70% of the overall dialogue in the script: 25%\n",
    "    3. If a male character has dialogue between 51% to 69% of the overall dialogue in the script: the percentage will be assigned on the basis of the percentile between values 0.1%-24.9%\n",
    "\n",
    "> **Graphs**\n",
    "> 1. bar chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The camera: SPARQL metadata retrieval\n",
    "\n",
    "Finally, after gathering some preliminary results from the first analyses on film scripts and IMDB's reviews, we further deepened our research using the [**Linked Internet Movie Database (IMDb)**](https://triplydb.com/Triply/linkedmdb) and its **SPARQL endpoint**, hosted on Triply.\n",
    "\n",
    "Not having knowledge about the structure of such knowledge base, an initial phase of **data exploration** was deemed necessary.\n",
    "\n",
    "Afterwards it was finally possible to perform the queries and save the results in an appropriate format as to visualize the data and gather insight on it.\n",
    "\n",
    "### Data exploration\n",
    "In general, there are two different types of statements (triples) in knowledge bases: **T-Box** statements and **A-Box** statements.\n",
    "1. **T-Box** (Terminological Box) statements describe the domain of interest defining classes and properties as the domain vocabulary; they contain information related to the **structure of the dataset**\n",
    "2. **A-Box** (Assertional Box) statements provide facts associated with the TBox's conceptual model or ontologies; they contain information on instances and the relationships between them: the **main content of the dataset**\n",
    "\n",
    "For the exploration of the IMDB dataset, we will follow this theoretical structure.\n",
    "\n",
    "#### T-Box (Terminological Box)\n",
    "A first interesting query would be to check the **number of triples** contained in the knowledge base, to get a flavor of the extent of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of triples is:\n",
      "    tripleCount\n",
      "0      6950066\n"
     ]
    }
   ],
   "source": [
    "# Import library to display the results cleanly\n",
    "import sparql_dataframe\n",
    "\n",
    "# Reference resource: IMDB SPARQL endpoint URL\n",
    "endpoint = 'https://api.triplydb.com/datasets/Triply/linkedmdb/services/linkedmdb/sparql'\n",
    "\n",
    "# Query we want to run: how many triples are in the LOD source?\n",
    "query_triples_count = '''\n",
    "    SELECT (COUNT (*) AS ?tripleCount)\n",
    "    WHERE {\n",
    "        ?s ?p ?o\n",
    "    }\n",
    "'''\n",
    "\n",
    "# Create dataframe and print it\n",
    "df = sparql_dataframe.get(endpoint, query_triples_count)\n",
    "print(f'The total number of triples is:\\n {df}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to quickly comprehend the kind of data available, we **listed the predicates used** (maybe listing them alphabetically), which immediately can tell us interesting facts on the kind of data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of predicates:\n",
      "                                                      p\n",
      "0       http://dbpedia.org/property/hasPhotoCollection\n",
      "1                        http://purl.org/dc/terms/date\n",
      "2                       http://purl.org/dc/terms/title\n",
      "3                       http://rdfs.org/ns/void#subset\n",
      "4    http://www.openlinksw.com/schemas/virtrdf#dialect\n",
      "..                                                 ...\n",
      "227  https://triplydb.com/Triply/linkedmdb/vocab/st...\n",
      "228  https://triplydb.com/Triply/linkedmdb/vocab/ty...\n",
      "229  https://triplydb.com/Triply/linkedmdb/vocab/wr...\n",
      "230  https://triplydb.com/Triply/linkedmdb/vocab/wr...\n",
      "231  https://triplydb.com/Triply/linkedmdb/vocab/wr...\n",
      "\n",
      "[232 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# List predicates \n",
    "query_predicates = '''\n",
    "    SELECT DISTINCT ?p\n",
    "    WHERE { \n",
    "    ?s ?p ?o .\n",
    "    } ORDER BY ?p\n",
    "'''\n",
    "\n",
    "df = sparql_dataframe.get(endpoint, query_predicates)\n",
    "print(f'The list of predicates:\\n {df}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presence of `rdfs:subClassOf` indicates the presence of some structure, while `dcterms:title` shows that the knowledge graph deals with works (clearly, this being a knowledge base on the Internet Movie Database contents), finally `foaf` indicates the presence of information about people. But these are only some of the many ontologies used in this knowledge graph.\n",
    "\n",
    "Having ordered the resulting dataframe in alphabetical order allows us to immediately and easily see the **many different ontologies** employed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://dbpedia.org/property/hasPhotoCollection\n",
      "http://purl.org/dc/terms/date\n",
      "http://purl.org/dc/terms/title\n",
      "http://rdfs.org/ns/void#subset\n",
      "http://www.openlinksw.com/schemas/virtrdf#dialect\n",
      "http://www.openlinksw.com/schemas/virtrdf#dialect-exceptions\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n",
      "http://www.w3.org/2000/01/rdf-schema#SeeAlso\n",
      "http://www.w3.org/2000/01/rdf-schema#label\n",
      "http://www.w3.org/2000/01/rdf-schema#subClassOf\n",
      "http://www.w3.org/2002/07/owl#sameAs\n",
      "http://www.w3.org/2004/02/skos/core#subject\n",
      "http://xmlns.com/foaf/0.1/based_near\n",
      "http://xmlns.com/foaf/0.1/made\n",
      "http://xmlns.com/foaf/0.1/page\n",
      "https://triplydb.com/Triply/linkedmdb/id/oddlinker/link_source\n",
      "https://triplydb.com/Triply/linkedmdb/id/oddlinker/link_target\n",
      "https://triplydb.com/Triply/linkedmdb/id/oddlinker/link_type\n",
      "https://triplydb.com/Triply/linkedmdb/id/oddlinker/linkage_date\n",
      "https://triplydb.com/Triply/linkedmdb/id/oddlinker/linkage_method\n",
      "https://triplydb.com/Triply/linkedmdb/id/oddlinker/linkage_run\n",
      "https://triplydb.com/Triply/linkedmdb/id/oddlinker/linkage_score\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/actor\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/actor_actorid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/actor_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/actor_netflix_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/actor_nytimes_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/cinematographer\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/cinematographer_cinematographerid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/cinematographer_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/content_rating_content_ratingid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/content_rating_country\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/content_rating_film_rating_system\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/content_rating_minimum_unaccompanied_age\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/content_rating_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/content_rating_system\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/content_rating_system_content_rating_systemid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/content_rating_system_jurisdiction\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/content_rating_system_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/costume_designer\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_areaInSqKm\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_capital\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_continent\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_currency\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_fips_code\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_iso_alpha2\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_iso_alpha3\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_iso_numeric\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_languages\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/country_population\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/crew_gig_film\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/crewmember\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/director\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/director_directorid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/director_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/dubbing_performance\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/dubbing_performance_actor\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/dubbing_performance_character\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/dubbing_performance_dubbing_performanceid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/dubbing_performance_film\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/dubbing_performance_language\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/dubbing_performance_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/editor\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/editor_editorid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/editor_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/executive_producer\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/featured_film_location\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_art_director\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_art_director_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_art_director_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_awards_ceremony_film_awards_ceremonyid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_awards_ceremony_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_awards_ceremony_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_casting_director\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_casting_director_film_casting_director_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_casting_director_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_casting_director_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_character\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_character_film_characterid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_character_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_collection\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_collection_film_collectionid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_collection_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_company\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_company_film_companyid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_company_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_costume_designer_film_costume_designerid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_costume_designer_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_crew_gig_film\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_crew_gig_film_crew_gigid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_crew_gig_film_job\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_crew_gig_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_crew_gig_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_crew_role\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_crewmember\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_crewmember_film_crewmemberid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_crewmember_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_critic_film_criticid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_critic_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_cut\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_cut_film_cutid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_cut_note\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_distribution_medium\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_distribution_medium_film_distribution_mediumid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_distribution_medium_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_distributor\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_distributor_film_distributorid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_distributor_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_distributor_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_featured_song\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_featured_song_film_featured_song_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_featured_song_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_featured_song_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_featured_song_performed_by\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_event\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_event_closing_date\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_event_film_festival_event_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_event_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_event_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_event_opening_date\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_film_festivalid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_focus_film_festival_focus_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_focus_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_focus_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_sponsor_film_festival_sponsor_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_sponsor_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_festival_sponsor_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_company_relationship\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_company_relationship_film_film_company_relationshipid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_company_relationship_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_company_relationship_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_company_relationship_role_service\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_distributor_relationship_distributor\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_distributor_relationship_film_cut\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_distributor_relationship_film_distribution_medium\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_distributor_relationship_film_film_distributor_relationshipid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_distributor_relationship_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_distributor_relationship_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_distributor_relationship_region\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_film_distributor_relationship_year\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_format\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_format_film_formatid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_format_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_genre_film_genreid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_genre_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_job_film_jobid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_job_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_location_film_locationid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_location_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_of_distributor\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_production_designer\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_production_designer_film_production_designer_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_production_designer_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_production_designer_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_regional_release_date\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_regional_release_date_film_regional_debut_venue\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_regional_release_date_film_regional_release_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_regional_release_date_film_release_distribution_medium\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_regional_release_date_film_release_region\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_regional_release_date_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_regional_release_date_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_regional_release_date_release_date\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_release_region\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_screening_venue_film_screening_venue_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_screening_venue_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_screening_venue_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_series\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_series_film_seriesid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_series_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_set_designer\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_set_designer_film_set_designer_id\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_set_designer_freebase_url\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_set_designer_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_story_contributor\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_story_contributor_film_story_contributorid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_story_contributor_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_subject\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_subject_film_subjectid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_subject_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_theorist_film_theoristid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/film_theorist_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/filmid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/genre\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/initial_release_date\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/language\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/linkid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/location\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/minor_film_genre_minor_film_genreid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/minor_film_genre_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/music_contributor\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/music_contributor_music_contributorid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/music_contributor_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/performance\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/performance_actor\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/performance_character\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/performance_film\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/performance_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/performance_note\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/performance_part\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/performance_performanceid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/performance_special_performance_type\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/personal_film_appearance\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/personal_film_appearance_film\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/personal_film_appearance_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/personal_film_appearance_person\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/personal_film_appearance_personal_film_appearanceid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/personal_film_appearance_type\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/personal_film_appearance_type_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/personal_film_appearance_type_of_appearance\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/personal_film_appearance_type_personal_film_appearance_typeid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/prequel\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/producer\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/producer_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/producer_producerid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/production_company\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/production_company_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/production_company_production_companyid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/rating\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/relatedBook\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/runtime\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/sequel\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/special_film_performance_type_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/special_film_performance_type_special_film_performance_typeid\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/story_contributor\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/type_of_film_cut\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/writer\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/writer_name\n",
      "https://triplydb.com/Triply/linkedmdb/vocab/writer_writerid\n"
     ]
    }
   ],
   "source": [
    "# Print each row of the dataframe\n",
    "for idx, row in df.iterrows():\n",
    "    print(row['p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have:\n",
    "- [DBpedia](https://www.dbpedia.org/)\n",
    "- [Dcterms](https://www.dublincore.org/specifications/dublin-core/dcmi-terms/)\n",
    "- [OWL](https://www.w3.org/TR/owl-features/)\n",
    "- [RDF Schema](https://www.w3.org/TR/rdf-schema/)\n",
    "- [SKOS](https://www.w3.org/TR/skos-reference/)\n",
    "- [FOAF](http://xmlns.com/foaf/0.1/)\n",
    "- [VoID](https://www.w3.org/TR/void/)\n",
    "- [Virtrdf](https://vos.openlinksw.com/owiki/wiki/VOS/VirtRDFViewNorthwindOntology)\n",
    "- Linkedimdb/id\n",
    "- Linkedimdb/vocab\n",
    "\n",
    "It is also interesting to understand which are the **most used properties**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of times each predicate is used:\n",
      "                                                      p  predicate\n",
      "0      http://www.w3.org/1999/02/22-rdf-syntax-ns#type     817073\n",
      "1           http://www.w3.org/2000/01/rdf-schema#label     722092\n",
      "2                       http://xmlns.com/foaf/0.1/page     577112\n",
      "3    https://triplydb.com/Triply/linkedmdb/vocab/pe...     390322\n",
      "4    https://triplydb.com/Triply/linkedmdb/vocab/actor     284409\n",
      "..                                                 ...        ...\n",
      "227  https://triplydb.com/Triply/linkedmdb/id/oddli...          7\n",
      "228                     http://rdfs.org/ns/void#subset          2\n",
      "229  http://www.openlinksw.com/schemas/virtrdf#dial...          1\n",
      "230  http://www.openlinksw.com/schemas/virtrdf#dialect          1\n",
      "231  https://triplydb.com/Triply/linkedmdb/vocab/fi...          1\n",
      "\n",
      "[232 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Most used predicates list\n",
    "query_predicate_repetition = '''\n",
    "    SELECT ?p (COUNT(?p) AS ?predicate)\n",
    "    WHERE { \n",
    "    ?s ?p ?o .\n",
    "    }\n",
    "    GROUP BY ?p\n",
    "    ORDER BY DESC(?predicate)\n",
    "'''\n",
    "\n",
    "df = sparql_dataframe.get(endpoint, query_predicate_repetition)\n",
    "print(f'The number of times each predicate is used:\\n {df}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting insight we get from this first exploration is the presence of an ontology specific to IMDB: **Linkedimdb.**\n",
    "\n",
    "As linkedmdb/id obviously contains only linkage knowledge, we are more interested in linkedmbd/vocab and, to further analyse it, we can select only those properties belonging to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of linkedimdb/vocab predicates:\n",
      "                                                      p\n",
      "0    https://triplydb.com/Triply/linkedmdb/vocab/actor\n",
      "1    https://triplydb.com/Triply/linkedmdb/vocab/ac...\n",
      "2    https://triplydb.com/Triply/linkedmdb/vocab/ac...\n",
      "3    https://triplydb.com/Triply/linkedmdb/vocab/ac...\n",
      "4    https://triplydb.com/Triply/linkedmdb/vocab/ac...\n",
      "..                                                 ...\n",
      "205  https://triplydb.com/Triply/linkedmdb/vocab/st...\n",
      "206  https://triplydb.com/Triply/linkedmdb/vocab/ty...\n",
      "207  https://triplydb.com/Triply/linkedmdb/vocab/wr...\n",
      "208  https://triplydb.com/Triply/linkedmdb/vocab/wr...\n",
      "209  https://triplydb.com/Triply/linkedmdb/vocab/wr...\n",
      "\n",
      "[210 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# List linkedimdb/vocab predicates \n",
    "query_predicates = '''\n",
    "    SELECT DISTINCT ?p\n",
    "    WHERE { \n",
    "        ?s ?p ?o .\n",
    "        FILTER regex(?p, \"https://triplydb.com/Triply/linkedmdb/vocab/\", \"i\")\n",
    "    }\n",
    "    ORDER BY ?p\n",
    "'''\n",
    "\n",
    "df = sparql_dataframe.get(endpoint, query_predicates)\n",
    "print(f'The list of linkedimdb/vocab predicates:\\n {df}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this as a sort of \"ordered vocabulary\" for easily finding and selecting the predicates that could be the most useful for our intended queries. \n",
    "\n",
    "Moving on to Classes, we first need to understand **how are Classes defined**: if through other ontologies such as `owl:Class`, `rdf:type`/`a` `rdfs:Class`, or autonomously by the dataset (the latter would mean no result to our queries, as it actually happens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of classes (rdfs:Class):\n",
      " Empty DataFrame\n",
      "Columns: [c]\n",
      "Index: []\n",
      "The list of classes (owl:Class):\n",
      " Empty DataFrame\n",
      "Columns: [c]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "query_classes_rdfs = '''\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT DISTINCT ?c\n",
    "    WHERE {\n",
    "        ?c a rdfs:Class .\n",
    "    }\n",
    "    ORDER BY ?c\n",
    "'''\n",
    "df1 = sparql_dataframe.get(endpoint, query_classes_rdfs)\n",
    "print(f'The list of classes (rdfs:Class):\\n {df1}')\n",
    "\n",
    "query_classes_owl = '''\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    SELECT DISTINCT ?c\n",
    "    WHERE {\n",
    "        ?c a owl:Class .\n",
    "    }\n",
    "    ORDER BY ?c\n",
    "'''\n",
    "df2 = sparql_dataframe.get(endpoint, query_classes_owl)\n",
    "print(f'The list of classes (owl:Class):\\n {df2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the lack of results, it is therefore clear that this dataset autonomously defines its classes. To gather the list of **class types** (alphabetically ordeered) we can look for the type of the concept describing a subject (either `rdf:type` or `a`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of Classes types:\n",
      "                                               concept\n",
      "0                     http://rdfs.org/ns/void#Dataset\n",
      "1                     http://xmlns.com/foaf/0.1/Agent\n",
      "2                    http://xmlns.com/foaf/0.1/Person\n",
      "3   https://triplydb.com/Triply/linkedmdb/id/oddli...\n",
      "4   https://triplydb.com/Triply/linkedmdb/id/oddli...\n",
      "5   https://triplydb.com/Triply/linkedmdb/vocab/Actor\n",
      "6   https://triplydb.com/Triply/linkedmdb/vocab/Ar...\n",
      "7   https://triplydb.com/Triply/linkedmdb/vocab/Ca...\n",
      "8   https://triplydb.com/Triply/linkedmdb/vocab/Ci...\n",
      "9   https://triplydb.com/Triply/linkedmdb/vocab/Co...\n",
      "10  https://triplydb.com/Triply/linkedmdb/vocab/Co...\n",
      "11  https://triplydb.com/Triply/linkedmdb/vocab/Co...\n",
      "12  https://triplydb.com/Triply/linkedmdb/vocab/Co...\n",
      "13  https://triplydb.com/Triply/linkedmdb/vocab/Di...\n",
      "14  https://triplydb.com/Triply/linkedmdb/vocab/Du...\n",
      "15  https://triplydb.com/Triply/linkedmdb/vocab/Ed...\n",
      "16   https://triplydb.com/Triply/linkedmdb/vocab/Film\n",
      "17  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "18  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "19  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "20  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "21  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "22  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "23  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "24  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "25  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "26  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "27  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "28  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "29  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "30  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "31  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "32  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "33  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "34  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "35  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "36  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "37  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "38  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "39  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "40  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "41  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "42  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "43  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "44  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "45  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "46  https://triplydb.com/Triply/linkedmdb/vocab/Mi...\n",
      "47  https://triplydb.com/Triply/linkedmdb/vocab/Mu...\n",
      "48  https://triplydb.com/Triply/linkedmdb/vocab/Pe...\n",
      "49  https://triplydb.com/Triply/linkedmdb/vocab/Pe...\n",
      "50  https://triplydb.com/Triply/linkedmdb/vocab/Pe...\n",
      "51  https://triplydb.com/Triply/linkedmdb/vocab/Pr...\n",
      "52  https://triplydb.com/Triply/linkedmdb/vocab/Pr...\n",
      "53  https://triplydb.com/Triply/linkedmdb/vocab/Sp...\n",
      "54  https://triplydb.com/Triply/linkedmdb/vocab/Wr...\n"
     ]
    }
   ],
   "source": [
    "query_concepts = '''\n",
    "    SELECT DISTINCT ?concept \n",
    "    WHERE {\n",
    "        ?s a ?concept .\n",
    "    }\n",
    "    ORDER BY ?concept\n",
    "'''\n",
    "df = sparql_dataframe.get(endpoint, query_concepts)\n",
    "print(f'The list of Classes types:\\n {df}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if we are more interested in the **linkedmdb/vocab Classes**, we can easily list them all and have an \"ordered vocabulary\" (the process is the same as for the predicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of imdb Classes types:\n",
      "                                               concept\n",
      "0   https://triplydb.com/Triply/linkedmdb/vocab/Actor\n",
      "1   https://triplydb.com/Triply/linkedmdb/vocab/Ar...\n",
      "2   https://triplydb.com/Triply/linkedmdb/vocab/Ca...\n",
      "3   https://triplydb.com/Triply/linkedmdb/vocab/Ci...\n",
      "4   https://triplydb.com/Triply/linkedmdb/vocab/Co...\n",
      "5   https://triplydb.com/Triply/linkedmdb/vocab/Co...\n",
      "6   https://triplydb.com/Triply/linkedmdb/vocab/Co...\n",
      "7   https://triplydb.com/Triply/linkedmdb/vocab/Co...\n",
      "8   https://triplydb.com/Triply/linkedmdb/vocab/Di...\n",
      "9   https://triplydb.com/Triply/linkedmdb/vocab/Du...\n",
      "10  https://triplydb.com/Triply/linkedmdb/vocab/Ed...\n",
      "11   https://triplydb.com/Triply/linkedmdb/vocab/Film\n",
      "12  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "13  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "14  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "15  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "16  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "17  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "18  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "19  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "20  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "21  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "22  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "23  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "24  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "25  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "26  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "27  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "28  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "29  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "30  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "31  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "32  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "33  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "34  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "35  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "36  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "37  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "38  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "39  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "40  https://triplydb.com/Triply/linkedmdb/vocab/Fi...\n",
      "41  https://triplydb.com/Triply/linkedmdb/vocab/Mi...\n",
      "42  https://triplydb.com/Triply/linkedmdb/vocab/Mu...\n",
      "43  https://triplydb.com/Triply/linkedmdb/vocab/Pe...\n",
      "44  https://triplydb.com/Triply/linkedmdb/vocab/Pe...\n",
      "45  https://triplydb.com/Triply/linkedmdb/vocab/Pe...\n",
      "46  https://triplydb.com/Triply/linkedmdb/vocab/Pr...\n",
      "47  https://triplydb.com/Triply/linkedmdb/vocab/Pr...\n",
      "48  https://triplydb.com/Triply/linkedmdb/vocab/Sp...\n",
      "49  https://triplydb.com/Triply/linkedmdb/vocab/Wr...\n"
     ]
    }
   ],
   "source": [
    "query_concepts_imdb = '''\n",
    "    SELECT DISTINCT ?concept \n",
    "    WHERE {\n",
    "        ?s a ?concept .\n",
    "        FILTER regex(?concept, \"https://triplydb.com/Triply/linkedmdb/vocab/\", \"i\")\n",
    "    }\n",
    "    ORDER BY ?concept\n",
    "'''\n",
    "df = sparql_dataframe.get(endpoint, query_concepts_imdb)\n",
    "print(f'The list of imdb Classes types:\\n {df}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check how many predicates are associated to each Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of properties per type in descending order:\n",
      "                                                  type  count\n",
      "0    https://triplydb.com/Triply/linkedmdb/vocab/Film     48\n",
      "1                    http://xmlns.com/foaf/0.1/Person     19\n",
      "2   https://triplydb.com/Triply/linkedmdb/vocab/Co...     15\n",
      "3   https://triplydb.com/Triply/linkedmdb/vocab/Fi...     13\n",
      "4   https://triplydb.com/Triply/linkedmdb/vocab/Fi...     12\n",
      "5   https://triplydb.com/Triply/linkedmdb/vocab/Pe...     12\n",
      "6   https://triplydb.com/Triply/linkedmdb/vocab/Actor     10\n",
      "7   https://triplydb.com/Triply/linkedmdb/vocab/Pe...      9\n",
      "8   https://triplydb.com/Triply/linkedmdb/vocab/Fi...      9\n",
      "9   https://triplydb.com/Triply/linkedmdb/vocab/Du...      9\n",
      "10  https://triplydb.com/Triply/linkedmdb/vocab/Co...      9\n",
      "11  https://triplydb.com/Triply/linkedmdb/id/oddli...      8\n",
      "12  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      8\n",
      "13  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      7\n",
      "14  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      7\n",
      "15                    http://xmlns.com/foaf/0.1/Agent      7\n",
      "16  https://triplydb.com/Triply/linkedmdb/vocab/Co...      6\n",
      "17  https://triplydb.com/Triply/linkedmdb/vocab/Mu...      6\n",
      "18  https://triplydb.com/Triply/linkedmdb/vocab/Wr...      6\n",
      "19  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      6\n",
      "20  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      6\n",
      "21  https://triplydb.com/Triply/linkedmdb/vocab/Di...      6\n",
      "22  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      6\n",
      "23  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "24  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "25  https://triplydb.com/Triply/linkedmdb/vocab/Pr...      5\n",
      "26  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "27  https://triplydb.com/Triply/linkedmdb/vocab/Ed...      5\n",
      "28  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "29  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "30  https://triplydb.com/Triply/linkedmdb/vocab/Ar...      5\n",
      "31  https://triplydb.com/Triply/linkedmdb/vocab/Co...      5\n",
      "32  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "33  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "34  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "35  https://triplydb.com/Triply/linkedmdb/vocab/Mi...      5\n",
      "36  https://triplydb.com/Triply/linkedmdb/vocab/Ca...      5\n",
      "37  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "38  https://triplydb.com/Triply/linkedmdb/vocab/Sp...      5\n",
      "39  https://triplydb.com/Triply/linkedmdb/vocab/Ci...      5\n",
      "40  https://triplydb.com/Triply/linkedmdb/vocab/Pe...      5\n",
      "41  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "42  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "43  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "44  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "45  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "46  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "47  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "48  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "49  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "50  https://triplydb.com/Triply/linkedmdb/vocab/Pr...      5\n",
      "51  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "52  https://triplydb.com/Triply/linkedmdb/vocab/Fi...      5\n",
      "53  https://triplydb.com/Triply/linkedmdb/id/oddli...      3\n",
      "54                    http://rdfs.org/ns/void#Dataset      2\n"
     ]
    }
   ],
   "source": [
    "query_property_per_type = '''\n",
    "    SELECT DISTINCT ?type (COUNT(DISTINCT ?p) AS ?count)\n",
    "    WHERE {\n",
    "        ?s a ?type . \n",
    "        ?s ?p ?o . \n",
    "    }\n",
    "    GROUP BY ?type\n",
    "    ORDER BY DESC(?count)\n",
    "'''\n",
    "\n",
    "df = sparql_dataframe.get(endpoint, query_property_per_type)\n",
    "print(f'The number of properties per type in descending order:\\n {df}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A-Box (Assertional Box)\n",
    "\n",
    "The instances of Classes are specifically the \"content\" of a dataset. A first query could then be to look at **how many instances each Class has**, being therefore able to see which are the most recurrent concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of instances per class are:\n",
      "                                               concept  instanceCount\n",
      "0   https://triplydb.com/Triply/linkedmdb/vocab/Pe...         199771\n",
      "1   https://triplydb.com/Triply/linkedmdb/id/oddli...         162199\n",
      "2    https://triplydb.com/Triply/linkedmdb/vocab/Film          98816\n",
      "3                    http://xmlns.com/foaf/0.1/Person          97858\n",
      "4   https://triplydb.com/Triply/linkedmdb/vocab/Actor          68205\n",
      "5   https://triplydb.com/Triply/linkedmdb/vocab/Fi...          45423\n",
      "6   https://triplydb.com/Triply/linkedmdb/vocab/Wr...          23664\n",
      "7   https://triplydb.com/Triply/linkedmdb/vocab/Di...          21966\n",
      "8   https://triplydb.com/Triply/linkedmdb/vocab/Pr...          18408\n",
      "9   https://triplydb.com/Triply/linkedmdb/vocab/Fi...          17237\n",
      "10  https://triplydb.com/Triply/linkedmdb/vocab/Fi...          16118\n",
      "11  https://triplydb.com/Triply/linkedmdb/vocab/Fi...          15256\n",
      "12  https://triplydb.com/Triply/linkedmdb/vocab/Mu...           6639\n",
      "13  https://triplydb.com/Triply/linkedmdb/vocab/Fi...           4048\n",
      "14  https://triplydb.com/Triply/linkedmdb/vocab/Ed...           3843\n",
      "15  https://triplydb.com/Triply/linkedmdb/vocab/Ci...           3819\n",
      "16  https://triplydb.com/Triply/linkedmdb/vocab/Pr...           1928\n",
      "17  https://triplydb.com/Triply/linkedmdb/vocab/Fi...           1463\n",
      "18  https://triplydb.com/Triply/linkedmdb/vocab/Fi...           1397\n",
      "19  https://triplydb.com/Triply/linkedmdb/vocab/Pe...           1127\n",
      "20  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            872\n",
      "21  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            840\n",
      "22                    http://xmlns.com/foaf/0.1/Agent            703\n",
      "23  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            685\n",
      "24  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            478\n",
      "25  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            418\n",
      "26  https://triplydb.com/Triply/linkedmdb/vocab/Ar...            365\n",
      "27  https://triplydb.com/Triply/linkedmdb/vocab/Co...            365\n",
      "28  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            338\n",
      "29  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            293\n",
      "30  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            283\n",
      "31  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            275\n",
      "32  https://triplydb.com/Triply/linkedmdb/vocab/Ca...            273\n",
      "33  https://triplydb.com/Triply/linkedmdb/vocab/Co...            247\n",
      "34  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            207\n",
      "35  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            206\n",
      "36  https://triplydb.com/Triply/linkedmdb/vocab/Fi...            169\n",
      "37  https://triplydb.com/Triply/linkedmdb/vocab/Du...            118\n",
      "38  https://triplydb.com/Triply/linkedmdb/vocab/Mi...            109\n",
      "39  https://triplydb.com/Triply/linkedmdb/vocab/Co...            108\n",
      "40  https://triplydb.com/Triply/linkedmdb/vocab/Fi...             96\n",
      "41  https://triplydb.com/Triply/linkedmdb/vocab/Fi...             72\n",
      "42  https://triplydb.com/Triply/linkedmdb/vocab/Fi...             70\n",
      "43  https://triplydb.com/Triply/linkedmdb/vocab/Co...             61\n",
      "44  https://triplydb.com/Triply/linkedmdb/vocab/Fi...             53\n",
      "45  https://triplydb.com/Triply/linkedmdb/vocab/Fi...             38\n",
      "46  https://triplydb.com/Triply/linkedmdb/vocab/Fi...             36\n",
      "47  https://triplydb.com/Triply/linkedmdb/vocab/Fi...             25\n",
      "48  https://triplydb.com/Triply/linkedmdb/vocab/Fi...             23\n",
      "49  https://triplydb.com/Triply/linkedmdb/vocab/Fi...             18\n",
      "50  https://triplydb.com/Triply/linkedmdb/vocab/Sp...             16\n",
      "51  https://triplydb.com/Triply/linkedmdb/vocab/Fi...             13\n",
      "52  https://triplydb.com/Triply/linkedmdb/vocab/Pe...              7\n",
      "53  https://triplydb.com/Triply/linkedmdb/id/oddli...              7\n",
      "54                    http://rdfs.org/ns/void#Dataset              1\n"
     ]
    }
   ],
   "source": [
    "query_instance_per_concept = '''\n",
    "    SELECT ?concept (COUNT (?s) AS ?instanceCount) \n",
    "    WHERE {\n",
    "    ?s a ?concept . \n",
    "    }\n",
    "    GROUP BY ?concept\n",
    "    ORDER BY DESC(?instanceCount)\n",
    "'''\n",
    "\n",
    "df = sparql_dataframe.get(endpoint, query_instance_per_concept)\n",
    "print(f'The number of instances per class are:\\n {df}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous analysis of the properties, we can see that the two most used properties are `rdf:type` and `rdf:label`. The issue of typographical errors (which multiplicate the same label) in labels is very important and, to get around it, we can use the `SAMPLE` construct, an aggregate function of SPARQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of instances with labels and repetitions:\n",
      "                                                instance  \\\n",
      "0     https://triplydb.com/Triply/linkedmdb/id/actor...   \n",
      "1     https://triplydb.com/Triply/linkedmdb/id/direc...   \n",
      "2     https://triplydb.com/Triply/linkedmdb/id/actor...   \n",
      "3     https://triplydb.com/Triply/linkedmdb/id/direc...   \n",
      "4     https://triplydb.com/Triply/linkedmdb/id/actor...   \n",
      "...                                                 ...   \n",
      "9995  https://triplydb.com/Triply/linkedmdb/id/actor...   \n",
      "9996  https://triplydb.com/Triply/linkedmdb/id/actor...   \n",
      "9997  https://triplydb.com/Triply/linkedmdb/id/actor...   \n",
      "9998  https://triplydb.com/Triply/linkedmdb/id/actor...   \n",
      "9999  https://triplydb.com/Triply/linkedmdb/id/actor...   \n",
      "\n",
      "                 instanceLabel  instanceCount  \n",
      "0          Bill Knight (Actor)              2  \n",
      "1      Susi Ganesan (Director)              2  \n",
      "2         Linda Haynes (Actor)              2  \n",
      "3          Lu Chuan (Director)              2  \n",
      "4     Ciccio Ingrassia (Actor)              2  \n",
      "...                        ...            ...  \n",
      "9995    Dorothy Arnold (Actor)              2  \n",
      "9996    Naveen Andrews (Actor)              2  \n",
      "9997       Fess Parker (Actor)              2  \n",
      "9998      Brian Werner (Actor)              2  \n",
      "9999   Arlette Marchal (Actor)              2  \n",
      "\n",
      "[10000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "query_instance_label = '''\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "    SELECT ?instance \n",
    "        (SAMPLE(?label) AS ?instanceLabel) \n",
    "        (COUNT(?instance) AS ?instanceCount) \n",
    "    WHERE { \n",
    "        ?instance a ?class . \n",
    "        OPTIONAL{ ?instance rdfs:label ?label .} \n",
    "        }\n",
    "        GROUP BY ?instance ?instanceLabel\n",
    "        ORDER BY DESC(?instanceCount)\n",
    "'''\n",
    "\n",
    "df = sparql_dataframe.get(endpoint, query_instance_label)\n",
    "print(f'The list of instances with labels and repetitions:\\n {df}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPARQL Queries\n",
    "\n",
    "We can now properly state our queries to the knowledge graph, and we do so based on the results coming from the **script analysis** and **review analysis** (respectively, the \"characters\" and the \"audience\" factors):\n",
    "- THE AUDIENCE RESULTS:\n",
    "    - some results here\n",
    "- THE CHARACTERS RESULTS:\n",
    "    - BECHDEL TEST results\n",
    "    - CHARACTER DIALOGUE results\n",
    "\n",
    "Queries:\n",
    "1. THE AUDIENCE QUERY\n",
    "2. THE CHARACTERS QUERY    \n",
    "    1. BECHDEL TEST: how many of the movies that **did not pass** the Bechdel test have **male directors**?\n",
    "    2. CHARACTER DIALOGUE: how many of the movies with a **majority of male dialogue** have **male writers**?\n",
    "3. GAZE SCORE\n",
    "    1. Compare the movies: what are their characteristics in terms of metadata?\n",
    "        > We can build different **scatterplots** to see whether there seems to be correlations between the movies or not (e.g. compare DIRECTOR, GENRE, DURATION)\n",
    "        1. We can also use RATING to see the popularity of each movie\n",
    "        2. CAST composition may be an interesting point to discuss\n",
    "        3. ...\n",
    "\n",
    "To query the SPARQL endpoint we will use the IMDB's ID of each movie, already contained in our `data/Dialogue/dialogue_bechdel.csv`, with the addition of the Wikidata's prefixes to distinguish between titles ('tt'), names ('nm'), characters ('ch', but deprecated), companies ('co'), events ('ev'), and news ('ni').\n",
    "\n",
    "Specifically, we will use the 'tt'+00 prefix.\n",
    "\n",
    "Director, genre, duration\n",
    "The input is going to be a movie list for the query (selected movies from the gaze score ranking)\n",
    "\n",
    "#### The \"Audience\" query\n",
    "#### The \"Characters\" queries\n",
    "#### Gaze score queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "- Abox, Wikipedia. https://en.wikipedia.org/wiki/Abox\n",
    "- \"How to explore an unknown dataset - quickstart\" by M. Daquino\n",
    "- DuCharme Bob, \"Exploring a SPARQL endpoint\", August 24, 2014. https://www.bobdc.com/blog/exploring-a-sparql-endpoint/.\n",
    "- DuCharme Bob, \"Queries to explore a dataset\", April 30, 2022. https://www.bobdc.com/blog/exploringadataset/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
