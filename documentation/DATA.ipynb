{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Through the Gaze - Data documentation\n",
    "This Jupyter Notebook analyses the data preparation and processing phase for [**Through the Gaze**](https://ahsanv101.github.io/ProjectGaze/), a project developed for the final exam of the course <a href=\"https://www.unibo.it/it/didattica/insegnamenti/insegnamento/2022/467047\">\"Information Visualization\"</a> held by professor Marilena Daquino at Alma Mater Studiorum - University of Bologna.\n",
    "\n",
    "For this project, we are interested in studying the concept of the **\"male gaze\"** in cinema, inspired by the essay \"Visual Pleasure and Narrative Cinema\" by the feminist film theorist Laura Mulvey. Mulvey underlines how the \"male gaze\" is made of three main components:\n",
    "1. The audience\n",
    "2. The characters\n",
    "3. The camera (i.e. the director)\n",
    "\n",
    "To represent a coherent and significant overview on the male gaze's impact on western cinematic industry, we will identify the **10 highest-grossing U.S. films for each decade from 1940s to 2010s**. The reason to opt for highest-grossing movies is that they give a general understanding of the popularity of the movie also in terms of fame and profit (highest grossing = surplus amount of people saw it), as well as produce a sort of cultural normativity.\n",
    "Taking highest-grossing movies per decade will help us generalize our results in terms of popularity.\n",
    "\n",
    "\n",
    "### Disclaimer \n",
    "This Jupyter Notebook is of informational nature only, it is not thought to be used for the data preparation and processing, but only for the analysis and explanation of such processes.\n",
    "<br>The Python files used for the clean up can be found in the `code` folder of the [Github repository](https://github.com/ahsanv101/ProjectGaze)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The audience: webscraping, sentiment and sexism\n",
    "Focusing on the audience component of the male gaze implied looking through some of the **reviews** provided for all the movies belonging to our dataset, and focusing not only on the overall reception of the movie, but mostly on the individuals' perception of it and possible gender bias underlying their opinion.\n",
    "\n",
    "\n",
    "Reviews are **not accompanied by the user that provided them**, since that was not useful for our analysis: what is important to keep in mind is that our reviews' dataset comprehends 1972 reviews related to our chosen movies, and that they are completely **public and available on the IMDB's reviews' pages**. Moreover, it's essential to underline that our analysis is partial and neutral, and hopes to elaborate useful reflections more than harsh critiques. \n",
    "\n",
    "### Reviews webscraping\n",
    "The first step of our audience's analysis comprehended a webscraping of the reviews' pages provided in the movie.csv files in URLs form. To do so, we used the [**BeautifulSoup library**](https://www.crummy.com/software/BeautifulSoup/) and we inspected the HTML structure of a standard IMDB's review's page: the textual content of any review is stored inside a `div` block marked by the tag \"text\", and here we access to all of our data. \n",
    "<br>\n",
    "The task, mostly automated, only required a division of the URLS into chunks, to speed up the overall scraping process (since we were working with huge amounts of data!). \n",
    "\n",
    "\n",
    "We later stored our reviews in a dictionary, then turned dataframe, then turned into a **`.csv` file**, containing a unique column, `Reviews`, alongside an index. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Orsola\\Documents\\GitHub\\ProjectGaze\\documentation\\DATA.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m chunk_resp\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m url_chunk \u001b[39min\u001b[39;00m url_chunks:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     scrape_batch(url_chunk)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m#From the list, we store our results into a dictionary, to later convert into a new dataframe and CSV. \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m reviews_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mReviews\u001b[39m\u001b[39m'\u001b[39m: text_reviews}\n",
      "\u001b[1;32mc:\\Users\\Orsola\\Documents\\GitHub\\ProjectGaze\\documentation\\DATA.ipynb Cell 3\u001b[0m in \u001b[0;36mscrape_batch\u001b[1;34m(url_chunk)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m chunk_resp \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m url_chunk:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     chunk_resp\u001b[39m.\u001b[39mappend(scrape_url(url))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mreturn\u001b[39;00m chunk_resp\n",
      "\u001b[1;32mc:\\Users\\Orsola\\Documents\\GitHub\\ProjectGaze\\documentation\\DATA.ipynb Cell 3\u001b[0m in \u001b[0;36mscrape_url\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscrape_url\u001b[39m(url):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(response\u001b[39m.\u001b[39;49mcontent, \u001b[39m\"\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mfor\u001b[39;00m links \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             review \u001b[39m=\u001b[39m links\u001b[39m.\u001b[39mget_text()\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39minitialize_soup(\u001b[39mself\u001b[39m)\n\u001b[0;32m    332\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed()\n\u001b[0;32m    334\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39m# Convert the document to Unicode.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mreset()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mfeed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarkup)\n\u001b[0;32m    452\u001b[0m \u001b[39m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendData()\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\builder\\_htmlparser.py:399\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    397\u001b[0m parser\u001b[39m.\u001b[39msoup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoup\n\u001b[0;32m    398\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     parser\u001b[39m.\u001b[39;49mfeed(markup)\n\u001b[0;32m    400\u001b[0m     parser\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    401\u001b[0m \u001b[39mexcept\u001b[39;00m HTMLParseError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\html\\parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[39mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39mas you want (may include '\\n').\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m+\u001b[39m data\n\u001b[1;32m--> 110\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoahead(\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\html\\parser.py:170\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m startswith(\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m, i):\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m starttagopen\u001b[39m.\u001b[39mmatch(rawdata, i): \u001b[39m# < + letter\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_starttag(i)\n\u001b[0;32m    171\u001b[0m     \u001b[39melif\u001b[39;00m startswith(\u001b[39m\"\u001b[39m\u001b[39m</\u001b[39m\u001b[39m\"\u001b[39m, i):\n\u001b[0;32m    172\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\html\\parser.py:342\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[39mreturn\u001b[39;00m endpos\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m end\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m/>\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    341\u001b[0m     \u001b[39m# XHTML-style empty tag: <span attr=\"value\" />\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_startendtag(tag, attrs)\n\u001b[0;32m    343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    344\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_starttag(tag, attrs)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\builder\\_htmlparser.py:119\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_startendtag\u001b[1;34m(self, name, attrs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39m\"\"\"Handle an incoming empty-element tag.\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \n\u001b[0;32m    110\u001b[0m \u001b[39mThis is only called when the markup looks like <tag/>.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39m:param attrs: Dictionary of the tag's attributes.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m# is_startend() tells handle_starttag not to close the tag\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m# just because its name matches a known empty-element tag. We\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39m# know that this is an empty-element tag and we want to call\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m# handle_endtag ourselves.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m tag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_starttag(name, attrs, handle_empty_element\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_endtag(name)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\builder\\_htmlparser.py:154\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_starttag\u001b[1;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39m#print(\"START\", name)\u001b[39;00m\n\u001b[0;32m    153\u001b[0m sourceline, sourcepos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetpos()\n\u001b[1;32m--> 154\u001b[0m tag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msoup\u001b[39m.\u001b[39;49mhandle_starttag(\n\u001b[0;32m    155\u001b[0m     name, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, attr_dict, sourceline\u001b[39m=\u001b[39;49msourceline,\n\u001b[0;32m    156\u001b[0m     sourcepos\u001b[39m=\u001b[39;49msourcepos\n\u001b[0;32m    157\u001b[0m )\n\u001b[0;32m    158\u001b[0m \u001b[39mif\u001b[39;00m tag \u001b[39mand\u001b[39;00m tag\u001b[39m.\u001b[39mis_empty_element \u001b[39mand\u001b[39;00m handle_empty_element:\n\u001b[0;32m    159\u001b[0m     \u001b[39m# Unlike other parsers, html.parser doesn't send separate end tag\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[39m# events for empty-element tags. (It's handled in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# don't want handle_endtag() to cross off any previous end\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# events for tags of this name.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_endtag(name, check_already_closed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:721\u001b[0m, in \u001b[0;36mBeautifulSoup.handle_starttag\u001b[1;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_only \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtagStack) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    717\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_only\u001b[39m.\u001b[39mtext\n\u001b[0;32m    718\u001b[0m          \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_only\u001b[39m.\u001b[39msearch_tag(name, attrs))):\n\u001b[0;32m    719\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m tag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49melement_classes\u001b[39m.\u001b[39;49mget(Tag, Tag)(\n\u001b[0;32m    722\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder, name, namespace, nsprefix, attrs,\n\u001b[0;32m    723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrentTag, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_most_recent_element,\n\u001b[0;32m    724\u001b[0m     sourceline\u001b[39m=\u001b[39;49msourceline, sourcepos\u001b[39m=\u001b[39;49msourcepos,\n\u001b[0;32m    725\u001b[0m     namespaces\u001b[39m=\u001b[39;49mnamespaces\n\u001b[0;32m    726\u001b[0m )\n\u001b[0;32m    727\u001b[0m \u001b[39mif\u001b[39;00m tag \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    728\u001b[0m     \u001b[39mreturn\u001b[39;00m tag\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\element.py:1243\u001b[0m, in \u001b[0;36mTag.__init__\u001b[1;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml, sourceline, sourcepos, can_be_empty_element, cdata_list_attributes, preserve_whitespace_tags, interesting_string_types, namespaces)\u001b[0m\n\u001b[0;32m   1241\u001b[0m \u001b[39melif\u001b[39;00m attrs:\n\u001b[0;32m   1242\u001b[0m     \u001b[39mif\u001b[39;00m builder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m builder\u001b[39m.\u001b[39mcdata_list_attributes:\n\u001b[1;32m-> 1243\u001b[0m         attrs \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39;49m_replace_cdata_list_attribute_values(\n\u001b[0;32m   1244\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, attrs)\n\u001b[0;32m   1245\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1246\u001b[0m         attrs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(attrs)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\builder\\__init__.py:315\u001b[0m, in \u001b[0;36mTreeBuilder._replace_cdata_list_attribute_values\u001b[1;34m(self, tag_name, attrs)\u001b[0m\n\u001b[0;32m    312\u001b[0m tag_specific \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcdata_list_attributes\u001b[39m.\u001b[39mget(\n\u001b[0;32m    313\u001b[0m     tag_name\u001b[39m.\u001b[39mlower(), \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    314\u001b[0m \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(attrs\u001b[39m.\u001b[39mkeys()):\n\u001b[1;32m--> 315\u001b[0m     \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m universal \u001b[39mor\u001b[39;00m (tag_specific \u001b[39mand\u001b[39;00m attr \u001b[39min\u001b[39;00m tag_specific):\n\u001b[0;32m    316\u001b[0m         \u001b[39m# We have a \"class\"-type attribute whose string\u001b[39;00m\n\u001b[0;32m    317\u001b[0m         \u001b[39m# value is a whitespace-separated list of\u001b[39;00m\n\u001b[0;32m    318\u001b[0m         \u001b[39m# values. Split it into a list.\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         value \u001b[39m=\u001b[39m attrs[attr]\n\u001b[0;32m    320\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mstr\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# We used the following libraries!\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "# Here we initialize and modify our CSVs accordingly and we create a list for the webscraped reviews \n",
    "movies = pd.read_csv('../data/webscrape/movies-checkpoint.csv')\n",
    "title_reviews = movies[['Title','Reviews']].copy()\n",
    "\n",
    "text_reviews = []\n",
    "\n",
    "# The webrascraping starts here\n",
    "batch_size = 79\n",
    "urls = ['https://www.imdb.com/title/tt0038969/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0041838/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0031381/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0037536/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0034167/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0036872/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0039391/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0035575/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0034583/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0040806/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0049833/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0045793/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0044672/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0044672/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0047673/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0043949/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0051459/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0053291/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0048593/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0042192/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0059742/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0061722/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0064115/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0058331/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0056937/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0062622/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0055614/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0054215/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0056172/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0060164/?ref_=nv_sr_srsg_3', 'https://www.imdb.com/title/tt0073195/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0076759/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0070047/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0077631/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0068646/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0071230/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0075148/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0066011/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0078346/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0067093/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0080684/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0083866/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0096895/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0086190/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0087332/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0088763/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0092099/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0092644/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0096438/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0081573/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0120338/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0120915/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0107290/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0116629/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0109830/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0119654/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0099653/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0103064/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0103776/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0112462/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0468569/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0383574/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0145487/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0417741/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0121766/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0316654/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0418279/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0325980/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0241527/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0120755/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt4154796/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt1825683/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt2488496/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0848228/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt2527336/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0499549/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0770828/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt3748528/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt1201607/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt1877832/reviews?ref_=tt_urv']\n",
    "url_chunks = [urls[x:x+batch_size] for x in range(0, len(urls), batch_size)]\n",
    "\n",
    "def scrape_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for links in soup.find_all('div', class_='text'):\n",
    "            review = links.get_text()\n",
    "            text_reviews.append(review)\n",
    "def scrape_batch(url_chunk):\n",
    "    chunk_resp = []\n",
    "    for url in url_chunk:\n",
    "        chunk_resp.append(scrape_url(url))\n",
    "    return chunk_resp\n",
    "for url_chunk in url_chunks:\n",
    "    scrape_batch(url_chunk)\n",
    "    \n",
    "# From the list, we store our results into a dictionary, to later convert into a new dataframe and CSV. \n",
    "reviews_dict = {'Reviews': text_reviews}\n",
    "text_reviews = pd.DataFrame.from_dict(reviews_dict)\n",
    "# text_reviews.to_csv(\"text_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "Now that our reviews were available, it was time to actually start working on our analysis: this second step focused mostly on **retrieving the sentiment of our reviews**: *are they positive or negative?*\n",
    "<br>\n",
    "This aspect was later used to understand if there were any strong correlations among the possible sexist tone of a review and its overall sentiment: for example, *how does a poor opinion on women affect the overall perception of a movie?* *Are negative reviews the most sexist?*\n",
    "\n",
    "\n",
    "To achieve a correct sentiment analysis, we used the [**library `NLTK`**](https://www.nltk.org/) and its **`VADER`**, a rule-based sentiment analyzer in which the terms are generally labeled as per their semantic orientation as either positive or negative. \n",
    "The result of this analysis was a **new dataframe** containing our `Reviews` column, a new `Scores` column (containing non-weighted sentiment analysis scores, divided into negative, neutral and positive values), a `Compound` column (weighted values between 0 and 1) and a `Sentiment` column, that provides a clear label distinguishing Positive reviews (pos) from Negative ones (neg). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "df = pd.read_csv('text_reviews.csv')\n",
    "\n",
    "# Here starts the sentiment analysis \n",
    "df.dropna(inplace=True)\n",
    "empty_objects = []\n",
    "for review in df.itertuples():\n",
    "     if type(review)==str:\n",
    "             if review.isspace():\n",
    "                     empty_objects.append(review)\n",
    "df.drop(empty_objects, inplace=True)\n",
    "\n",
    "# We calculate overall scores, compound value and the sentiment label. \n",
    "df['scores'] = df['Reviews'].apply(lambda Reviews: vader.polarity_scores(Reviews))\n",
    "df['compound'] = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df['sentiment'] = df['compound'].apply(lambda c: 'pos' if c >= 0 else 'neg')\n",
    "\n",
    "#... And then we obtain the CSV\n",
    "# df.to_csv('sentiment_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sexism Analysis\n",
    "Having cleared the overall sentiment of our reviews, the final step of our audience's analysis comprehended **detecting possible traces of sexism in the reviews**.\n",
    "<br>\n",
    "To do this, we applied a model created and published by the group NLP-LTU on Hugging Face, the [**BerTweet Large Sexism Detector**](https://huggingface.co/NLP-LTU/bertweet-large-sexism-detector), a classification model for detecting sexism in Tweets or short text paragraphs. As some of our reviews were longer than the model's length limit, a few adjustments were implemented.\n",
    "\n",
    "\n",
    "At the end, we obtained a clear result: our reviews were not sexist or, at least, they were *not completely* sexist.\n",
    "<br>\n",
    "BERT categorized them as lacking any kind of gender bias, but, having inspected the reviews ourselves, we knew this was not true: a few reviews showed clear signs of misogyny and sexism, not just by using offensive words such as \"bitch\" or \"tramp\" when referring to actresses or their characters, but by constantly describing them as sexy and beautiful or by comparing them to animals. \n",
    "BERT simply failed to recognized them because, if considered in a quantified way, those sentences weighted very little in the general structure of the review, that otherwise had a very neutral or even positive tone. \n",
    "What emerged from this analysis, is that **the audience's gaze is rarely guided by pure prejudice or malevolence**: realistically, our reviews displayed sexism in a \"natural\" and subtle way, so subtle that even the sexism-detector model failed to aknowledge them when analysing the bigger picture. \n",
    "\n",
    "However, we were not satisfied with this result: we wanted to isolate these instances of sexism, and to do so, we needed to narrow the detector's scope of analysis. Therefore, we introduced a simpler function capable of dividing any reviews into smaller sentences: by doing this, we could obtain singular scores of sexism and give them more significance. \n",
    "If a review had a singular sexist sentence, was therefore marked as sexist, and sorted into the final CSV accordingly to its final sexist score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this code to work, the libraries Transformers and Torch are needed. \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer,pipeline\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "#We define the model, tokenizer and classifier we are going to use \n",
    "model = AutoModelForSequenceClassification.from_pretrained('NLP-LTU/bertweet-large-sexism-detector')\n",
    "tokenizer = AutoTokenizer.from_pretrained('NLP-LTU/bertweet-large-sexism-detector') \n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "df = pd.read_csv('sentiment_reviews.csv')\n",
    "\n",
    "\n",
    "#This portion of codes generates a prediction of the OVERALL review. According to the tensor size, it proceeds directly with the prediction or it adds an ulterior preprocessing and tokenization phase. \n",
    "import math\n",
    "\n",
    "for item in df['Reviews']: \n",
    "  if (len(item.split())>512):\n",
    "    n=math.ceil(len(item.split())/512)\n",
    "    for i in range(n):\n",
    "        if (i==(n-1)):\n",
    "          safe_item=' '.join(item.split()[i*512::])  \n",
    "        else:\n",
    "          item=' '.join(item.split()[i*512:(i+1)*512])\n",
    "          tokenized = tokenizer.encode(item, padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
    "          prediction = classifier(str(tokenized))\n",
    "          print(prediction, item)\n",
    "          \n",
    "#To work on the individual sentences, we used this instead. \n",
    "\n",
    "reviews = []\n",
    "sentences = []\n",
    "\n",
    "for index, item in df.Reviews.items(): \n",
    "      sentence = item.split('.')      \n",
    "      prediction = classifier(sentence)\n",
    "      sentences.append(sentence)  \n",
    "      reviews.append(prediction)\n",
    "      print([sentence, prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The characters: film and scripts analysis\n",
    "The aim of this analysis is to extract the dominance of the male gaze in the scope of the film and script. This is one of the most important analysis as we also directly dive into the core content of the cinema industry which are the scripts, the basis of any film. The reason we chose scripts is because they address **the whole setting of the characters** as well as **how they are defined on the camera** (viewers) and **how the male character in the script perceives the non-male ones**. They also show what kind of dialogues or actions are assigned to male ones vs non male and give us a good comparative analysis. \n",
    "\n",
    "\n",
    "### Bechdel Test\n",
    "The first step into this analysis is the infamous [Bechdel Test](https://bechdeltest.com/), used for measuring **how women are represented in a given film**. There are generally three rules that a film needs to pass:\n",
    "\n",
    "1. The movie has to have at least two women in it\n",
    "2. The movie has to have at least two women who talk to each other\n",
    "3. The movie has to have at least two women who talk to each other and it is about something other than a man\n",
    "\n",
    "If a movie passes all three of the rules then it passes the Bechdel test. This goes to show a very bare minimum bar that ideally every movie should have. We will collect that data from already <a href= \"https://www.kaggle.com/datasets/alisonyao/movie-bechdel-test-scores\">existing datasets</a> and check the results with the scope of our movies. \n",
    "\n",
    "After importing our datasets and performing string cleaning for merging correctly, we assign the corresponding bechdel test values to our given films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "cwd = os.getcwd()\n",
    "path =\"/\".join(list(cwd.split('/')[0:-1])) \n",
    "\n",
    "top_movies = path+'/Data/webscrape/finalmovies.csv'\n",
    "movies_df = pd.read_csv(top_movies,header=0)\n",
    "bechdel_data=path+'/Data/bechdel/Bechdel_detailed.csv'\n",
    "bechdel_df= pd.read_csv(bechdel_data)\n",
    "bechdel_df.rename(columns={\"title\":\"Title\"}, inplace=True)\n",
    "bechdel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains information and metadata regarding the bechdel evaluation for a series of movies.\n",
    "The information most relevant to us the <b>rating column</b> that contains a number from 0 to 3, where:\n",
    "<ul>\n",
    "<li>0 means there are no two female characters, </li>\n",
    "<li>1 means if they exist, there is no talking between them, </li>\n",
    "<li>2 means if they talk, it is only  about a man,</li>\n",
    "<li>3 means it passes the test;</li>\n",
    "\n",
    "</ul>\n",
    "the column dubious states the submitter considered the rating dubious.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform cleaning and merging operations in order to get our final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Rename manually\n",
    "bechdel_df.loc[bechdel_df['Title'].str.contains('Rogue One'), 'Title'] = bechdel_df['Title'].str.replace('Rogue One', 'Rogue One: A Star Wars Story')\n",
    "bechdel_df.loc[bechdel_df['Title'].str.contains('Last Jedi'), 'Title'] = bechdel_df['Title'].str.replace('Star Wars: The Last Jedi', 'Star Wars: Episode VIII - The Last Jedi')\n",
    "bechdel_df.loc[bechdel_df['Title'].str.fullmatch('Star Wars'), 'Title'] = bechdel_df['Title'].str.replace('Star Wars', 'Star Wars: Episode IV - A New Hope')\n",
    "\n",
    "# Remove special characters etc\n",
    "def normalize_string(s):\n",
    "    s = s.replace('&#39;','')\t\n",
    "    s = s.replace(\"'\", '')  # apostrophes with empty string\n",
    "    s = re.sub(r'\\W+', '', s)  # Remove non-alphanumeric \n",
    "    s = s.lower()  # Convert to lowercase\n",
    "    s = s.replace(' ', '_') \n",
    "    s = s.replace('the', '')# Replace spaces with underscores\n",
    "    s = s.replace('judgment', 'judgement')\n",
    "    return s\n",
    "\n",
    "\n",
    "bechdel_df['name_normalized'] = bechdel_df['Title'].apply(normalize_string)\n",
    "movies_df['name_normalized'] = movies_df['Title'].apply(normalize_string)\n",
    "\n",
    "final_df = pd.merge(bechdel_df, movies_df, on='name_normalized', how='right')\n",
    "\n",
    "# Study missing values\n",
    "\n",
    "null_values_x= final_df['Title_x'].isna()\n",
    "null_values_x.sum()\n",
    "final_df[null_values_x]\n",
    "\n",
    "bechdel_no_data= final_df[null_values_x]\n",
    "bechdel_no_data = bechdel_no_data.drop([\"Unnamed: 0\",\"name_normalized\"], axis=1)\n",
    "bechdel_no_data = bechdel_no_data.dropna(axis=1)\n",
    "bechdel_no_data.rename(columns={\"Title_y\":\"Title\"}, inplace= True)\n",
    "bechdel_no_data.reset_index(drop=True, inplace=True) #these are our movies that do not have any data regarding bechdel rules\n",
    "\n",
    "# View movies that do not contain information\n",
    "bechdel_no_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 of our selected movies, most of them released in the beginning of our time range, have not yet been evaluated.\n",
    "Let's look at the information regarding the rest of the movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_bechdel = final_df.drop(['Unnamed: 0','submitterid','date','name_normalized', 'id','visible','Title_x'],axis=1)\n",
    "movies_bechdel.rename(columns={\"Title_y\":\"Title\",\"rating\":\"bechdel_rating\"}, inplace= True)\n",
    "movies_bechdel = movies_bechdel[['Title', 'Decade', 'Genre', 'Director', 'year', 'bechdel_rating', 'dubious']]\n",
    "\n",
    "title_duplicates = movies_bechdel[movies_bechdel['Title'].duplicated(keep=False)]\n",
    "# Drop duplicates by their index\n",
    "movies_bechdel= movies_bechdel.drop([24,25,29,77])\n",
    "movies_bechdel.reset_index(drop=True, inplace=True)\n",
    "\n",
    "movies_bechdel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more specific information we can query the dataframe directly, for example if we want to take a look at which of our selected films have passed the bechdel test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bechdel_passed = movies_bechdel[movies_bechdel[\"bechdel_rating\"] == 3.0] \n",
    "bechdel_passed.reset_index(drop=True, inplace=True)\n",
    "bechdel_passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "### Character Description\n",
    "In this step we will be diving into the **actual descriptions of characters in the scripts**. The idea of using descriptions of the characters is to get an understanding of how the camera wants to show certain features of the characters through the use of angles: in this way the camera becomes the gaze and the (non-male) character becomes the object for the gaze.\n",
    "\n",
    "Our aim is to extract automatically such descriptions from the scripts using Natural Language Processing and show the words which are often used in the describing characters (both male and non-male), revealing the differences in the way they are portayed. We also aim to **categorize female descriptions** in terms of *body descriptions* relating to the male gaze, and *dubious but problematic* descriptions relating to both the body and the personality of female characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# reading the script files\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "#nltk tools\n",
    "import nltk \n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "part = wn.synsets('body_part')[0]\n",
    "\n",
    "def is_body_part(candidate):\n",
    "    for ss in wn.synsets(candidate):\n",
    "        # only get those where the synset matches exactly\n",
    "        name = ss.name().split(\".\", 1)[0]\n",
    "        if name != candidate:\n",
    "            continue\n",
    "        hit = part.lowest_common_hypernyms(ss)\n",
    "        if hit and hit[0] == part:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "path =\"/\".join(list(cwd.split('/')[0:-1])) \n",
    " \n",
    "# assign directory\n",
    "directory = path+'/Data/scripts'\n",
    " \n",
    "# iterate over script files\n",
    "ignore='.DS_Store'\n",
    "files = []\n",
    "for filename in os.scandir(directory):\n",
    "\n",
    "     if filename.is_file() and ignore not in str(filename):\n",
    "        files.append(filename.path)\n",
    " \n",
    "def get_title(file_name): #get/clean script titles\n",
    "    title = file_name.split(\"/\")[-1]\n",
    "    \n",
    "    return title\n",
    "\n",
    "# keywords to look out for (body descriptions and adjectives). The last two lists contain problematic vocabulary often associated with females.\n",
    "\n",
    "words_0= ['body', 'blonde', 'brunette', 'lips', 'beauty', 'age', 'smile', 'pants', 'skirt', 'dress', 'shirt', 'glow', 'shorts', 'hand','face','finger', 'throat','neck','hair','skin','arm','figure','shoulder'] \n",
    "adj_0=['beautiful', 'gorgeous', 'cute', 'pretty', 'devoted','divine', 'lawful','housewife', 'silly', 'frightening']\n",
    "words_1=['ass', 'buxom','chest','boob', 'boob', 'bosom','buttock','breast', 'breasts','thigh', 'bottom', 'curve', 'underwear','thong','figure' 'panty', 'stocking', 'panties', 'lingerie', 'bra', 'nipple','vagina','cunt','womanhood']\n",
    "adj_1= ['seductive','sexy','trashy', 'nude', 'sexuality','promiscuous', 'sexual', 'ignorant', 'hot', 'hottie', 'erotic','fuck-me', 'fuck me','juicy','sultry', 'banging','naked', 'topless',\n",
    "        'stupid','helpless','fragile','dumb','weak','pitiful','enchanting', 'stunning','toned', 'breathtaking', 'breath-taking', 'perfect', 'bitch','slut','crazy',\n",
    "        'sassy','dramatic','bubbly','hysterical', 'bitchy','catty','tease','prude','trollop']\n",
    "\n",
    "\n",
    "# dictionary to store the data for each movie, for lists words_0 and adj_0\n",
    "movies_dict={}\n",
    "# dictionary  to store the data for each movie, for lists words_1 and adj_1\n",
    "movies_dict_1={}\n",
    "\n",
    "\n",
    "\n",
    "for f in files:\n",
    "    movie_title = get_title(f)\n",
    "    reader = PdfReader(f)\n",
    "    lst=[]\n",
    "    for i in range(0,len(reader.pages)):\n",
    "        page = reader.pages[i]\n",
    "        text = page.extract_text()\n",
    "        lst.append(text)\n",
    "\n",
    "    # dictionaries to store words and their number of occurences, for each list (body depiction and dubious words)\n",
    "    word_counts={}\n",
    "    word_counts_1={}\n",
    "    \n",
    "    check = [\"she\", \"her\", \"woman\", \"woman's\", \"women\", \"women's\", \"she's\",\"girl\",\"girl's\",\"girls\"]\n",
    "\n",
    "    for i in lst:\n",
    "        tokens = word_tokenize(i)\n",
    "\n",
    "        for k in range(0,len(tokens)):\n",
    "            # lemmatize\n",
    "            tokens[k] = lemmatizer.lemmatize(tokens[k])\n",
    "\n",
    "            # if the token is a body part or in the list of keywords\n",
    "            if is_body_part(tokens[k].lower()) == True or tokens[k].lower() in words_0+adj_0:  \n",
    "                \n",
    "                #get the n-grams near the token\n",
    "                gram2 = tokens[k-2].lower()\n",
    "                gram1 = tokens[k-1].lower()\n",
    "                gram = tokens[k].lower()\n",
    "                if k+1 in range(-len(tokens), len(tokens)):\n",
    "                  gram0 = tokens[k+1].lower()\n",
    "\n",
    "                # check whether they are associated with female pronouns\n",
    "                if  gram2 in check or gram1 in check or gram0 in check:\n",
    "\n",
    "                  #populate the dictionary\n",
    "                  if tokens[k].lower() in word_counts:\n",
    "                      word_counts[tokens[k].lower()] += 1\n",
    "                  else:\n",
    "                      word_counts[tokens[k].lower()] = 1\n",
    "\n",
    "            # if the token is in the list of our problematic keywords\n",
    "            if tokens[k].lower() in words_1+adj_1:\n",
    "\n",
    "                # check the n-grams around the problematic token\n",
    "                gram2 = tokens[k-2].lower()\n",
    "                gram1 = tokens[k-1].lower()\n",
    "                gram = tokens[k].lower()\n",
    "                if k+1 in range(-len(tokens), len(tokens)):\n",
    "                  gram0 = tokens[k+1].lower()\n",
    "\n",
    "                # check whether they are associated with female pronouns\n",
    "                if gram2 in check or gram1 in check or gram in check or gram0 in check:\n",
    "            \n",
    "                    # populate the dictionary for problematic keyword occurences\n",
    "                    if tokens[k].lower() in word_counts_1:\n",
    "                        word_counts_1[tokens[k].lower()] += 1\n",
    "                    else:\n",
    "                        word_counts_1[tokens[k].lower()] = 1\n",
    "    \n",
    "    # assign findings to the general dictionary for each key that is our movie\n",
    "    movies_dict[movie_title] = word_counts\n",
    "    movies_dict_1[movie_title] = word_counts_1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The above code iterates over the scripts in our folder, and looks for:\n",
    "<ul>\n",
    "    <li>words that are used to describe one's body, with the function \"is_body_part\", </li>\n",
    "    <li> words that we have deemed inappropriate for describing a female's body and character, given in a list of strings.</li>\n",
    "    \n",
    "</ul>\n",
    "</p>\n",
    "<p>Then, if these words are associated with <b>female characters</b> -through specific words and pronouns- they are added in their corresponding dictionaries, where each key is the movie name, whose key is a dictionary containing the words and the number of their occurence.</p>\n",
    "\n",
    "Let's take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('descriptions:',list(movies_dict.items())[0],'\\n','problematic descriptions:',list(movies_dict_1.items())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next, we want to create a dataframe with our all occurences for each film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get total amount for each movie\n",
    "movie_stats = {movie: sum(words.values()) for movie, words in movies_dict.items()}\n",
    "movie_stats_inapp = {movie: sum(words.values()) for movie, words in movies_dict_1.items()}\n",
    "\n",
    "movie_descriptions = DataFrame.from_dict(movie_stats, orient='index', columns=['count'])\n",
    "movie_descriptions_inapp= DataFrame.from_dict(movie_stats_inapp, orient='index', columns=['inappropriate_count'])\n",
    "\n",
    "movie_descriptions.reset_index(inplace=True)\n",
    "movie_descriptions_inapp.reset_index(inplace=True)\n",
    "\n",
    "movie_descriptions = movie_descriptions.rename(columns={'index':'script_name'})\n",
    "movie_descriptions_inapp = movie_descriptions_inapp.rename(columns={'index':'script_name'})\n",
    "\n",
    "movie_desc_graph= merge(movie_descriptions,movie_descriptions_inapp, left_on='script_name', right_on='script_name')\n",
    "\n",
    "\n",
    "# difflib  will allow us to match our script names to the appropriate movie titles\n",
    "\n",
    "import difflib\n",
    "df_all_movies = read_csv(path+'/Data/Dialogue/dialogue_bechdel.csv')\n",
    "import difflib\n",
    "titles = df_all_movies['Title'].to_list()\n",
    "titles_to_check= movie_desc_graph['script_name'].to_list()\n",
    "titles_match=[]\n",
    "for i in titles_to_check:\n",
    "    titles_match.append(difflib.get_close_matches(i, titles, len(titles), 0)[0])\n",
    "\n",
    "fem_desc_graph = DataFrame(list(zip(titles_match,titles_to_check)),\n",
    "               columns =['movie', 'script_name'])\n",
    "fem_desc_graph  = fem_desc_graph.merge(movie_desc_graph, left_on=\"script_name\", right_on= \"script_name\")\n",
    "fem_desc_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Character Dialogue\n",
    "In this step we are extracting all the dialogues spoken by male and non-male characters for each script automatically also using NLP tasks. The aim here is to show just how much the **division and representation of words** are given to men vs non-men characters. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing required modules\n",
    "from PyPDF2 import PdfReader\n",
    "import nltk \n",
    "from nltk.corpus import wordnet as wn\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import gender_guesser.detector as gender\n",
    "import csv\n",
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    " \n",
    "# nltk.download('wordnet')\n",
    "\n",
    "part = wn.synsets('body_part')[0]\n",
    "\n",
    "\n",
    "# assign directory\n",
    "directory = '../Data/scripts/'\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "\n",
    "files = []\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        files.append(filename.path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next sections of the code first we read through all the scripts page by page. Each page have multiple texts on it that re retrieve. From there are we start our language computational work. Since we scripts are generally written in an agreed upon format, we take it from there to make our code adapt to our format. This format generally means that we are aiming to extract all the characters which are written in the middle of the page, which is followed by their dialogues. \n",
    "\n",
    "\n",
    "For each page, we extract all the text. Then from those text, using some helper-functions, we extract the names of each character and their dialogues. We do this using dictionary as a data structure. Where the key becomes the character and the value becomes all their dialogues. Then each of these dictionaries are stored in a main dictionary with the script file name as key and the dictionary of character-dialogues as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This function is used to check if there is any word which is wither an upper case or as length 1 or 0 or if it has : in it\n",
    "def checkUpper(s):\n",
    "    if len(s) > 1 and s.isupper() != True:\n",
    "        if \":\" in e:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    elif len(s) == 1 or len(s) == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# This function simply checks if there are any numbers in the string\n",
    "def has_numbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "# files = ['../Data/scripts/ET_1.pdf']\n",
    "# Data/scripts/avatar.php','Data/scripts/batmanforever.php'\n",
    "# 'Data/scripts/backtothefuture.pdf\n",
    "# dic={}\n",
    "\n",
    "# This is the main dictionary where everything will be eventually stored\n",
    "\n",
    "\n",
    "Maindic = {}\n",
    "for f in files:\n",
    "    dic = {}\n",
    "\n",
    "    title = f.split(\"/\")[-1]\n",
    "    print('\\n', '---------------------------------', title,\n",
    "          '----------------------------------', '\\n')\n",
    "    reader = PdfReader(f)\n",
    "\n",
    "    lst = []\n",
    "\n",
    "    # for each page that the reader has read from the pdf\n",
    "    for i in range(0, len(reader.pages)):\n",
    "\n",
    "        page = reader.pages[i]\n",
    "        text = page.extract_text()\n",
    "#         splitting the text of the page on the basis of new line\n",
    "        ls = text.split('\\n')\n",
    "\n",
    "        for j in range(0, len(ls)):\n",
    "\n",
    "            #             for each line we clean it\n",
    "            cleaned = ls[j].strip()\n",
    "\n",
    "# Then we check if it is one word or two words or if it has : in it .\n",
    "# this is to basically extract that this will be a character who will be saying some dialgoue\n",
    "            if (len(cleaned.split(\" \")) == 1 or len(cleaned.split(\" \")) == 2) and (cleaned.isupper() or \":\" in cleaned) and '!' not in cleaned and has_numbers(cleaned) == False:\n",
    "\n",
    "                #             Then we check of the word index that we are iterating over has 6 lines or not. We do this check for 5,4,3 lines too\n",
    "\n",
    "                if j+6 in range(-len(ls), len(ls)):\n",
    "                    #                     Here we are adding all the lines together in one dialogue\n",
    "                    word = ls[j+1].strip()+' '+ls[j+2].strip()+' '+ls[j+3].strip() + \\\n",
    "                        ' '+ls[j+4].strip() + ' '+ls[j+5].strip() + \\\n",
    "                        ' '+ls[j+6].strip()\n",
    "\n",
    "                    newword = []\n",
    "#             Here we are checking all the lines that we added. we want to see if all the lines are actually dialogoues and not\n",
    "# continuation of some other character dialogue so we use the checkUpper function and break it whereever theres a doubt\n",
    "\n",
    "                    for e in word.split(' '):\n",
    "\n",
    "                        if checkUpper(e):\n",
    "                            newword.append(e)\n",
    "                        else:\n",
    "                            break\n",
    "#                     print(newword)\n",
    "\n",
    "                    word = ' '.join(newword)\n",
    "\n",
    "#                     Then we assign the character name to a local dictionary and all the dialogues will become the values\n",
    "                    if ls[j] not in dic:\n",
    "\n",
    "                        dic[ls[j].strip()] = word\n",
    "\n",
    "                    else:\n",
    "                        dic[ls[j].strip()] = dic[ls[j]] + ' '+word\n",
    "\n",
    "                elif j+5 in range(-len(ls), len(ls)):\n",
    "\n",
    "                    word = ls[j+1].strip()+' '+ls[j+2].strip()+' '+ls[j +\n",
    "                                                                      3].strip()+' '+ls[j+4].strip() + ' '+ls[j+5].strip()\n",
    "                    newword = []\n",
    "\n",
    "                    for e in word.split(' '):\n",
    "\n",
    "                        if checkUpper(e):\n",
    "                            newword.append(e)\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    word = ' '.join(newword)\n",
    "\n",
    "                    if ls[j] not in dic:\n",
    "\n",
    "                        dic[ls[j].strip()] = word\n",
    "\n",
    "                    else:\n",
    "                        dic[ls[j].strip()] = dic[ls[j]] + ' '+word\n",
    "\n",
    "                elif j+4 in range(-len(ls), len(ls)):\n",
    "                    word = ls[j+1].strip()+' '+ls[j+2].strip()+' ' + \\\n",
    "                        ls[j+3].strip()+' '+ls[j+4].strip()\n",
    "                    newword = []\n",
    "\n",
    "                    for e in word.split(' '):\n",
    "\n",
    "                        if checkUpper(e):\n",
    "                            newword.append(e)\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    word = ' '.join(newword)\n",
    "\n",
    "                    if ls[j] not in dic:\n",
    "\n",
    "                        dic[ls[j].strip()] = word\n",
    "\n",
    "                    else:\n",
    "                        dic[ls[j].strip()] = dic[ls[j]] + ' '+word\n",
    "\n",
    "\n",
    "#                 Doing for 3 lines because the above code already caters to the lines that already exist\n",
    "\n",
    "                elif j+3 in range(-len(ls), len(ls)):\n",
    "                    word = ls[j+1].strip()+' '+ls[j+2].strip() + \\\n",
    "                        ' '+ls[j+3].strip()\n",
    "                    newword = []\n",
    "\n",
    "                    for e in word.split(' '):\n",
    "\n",
    "                        if checkUpper(e):\n",
    "                            newword.append(e)\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    word = ' '.join(newword)\n",
    "\n",
    "                    if ls[j] not in dic:\n",
    "\n",
    "                        dic[ls[j].strip()] = word\n",
    "\n",
    "                    else:\n",
    "                        dic[ls[j].strip()] = dic[ls[j]] + ' '+word\n",
    "\n",
    "        Maindic[title] = dic\n",
    "#     Here is where we save each of the dic for each script in a main dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#   saving in a txt file\n",
    "with open('convert.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(Maindic))\n",
    "    \n",
    "\n",
    "# reading the data from the file\n",
    "with open('convert.txt') as f:\n",
    "    data = f.read()\n",
    "  \n",
    "\n",
    "      \n",
    "# # reconstructing the data as a dictionary\n",
    "js = json.loads(data)\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the characters, with their names as written on the scripts, we try to get the gender of these characters. We use the python gender guesser library for that purpose. \n",
    "\n",
    "It is important to know that these values were also manually checked in case there was a discrepency. Also that many characters which are not really male or female were not marked as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ahsan\\OneDrive\\Desktop\\ProjectGaze\\documentation\\DATA.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ahsan/OneDrive/Desktop/ProjectGaze/documentation/DATA.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m d \u001b[39m=\u001b[39m gender\u001b[39m.\u001b[39mDetector(case_sensitive\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ahsan/OneDrive/Desktop/ProjectGaze/documentation/DATA.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data\u001b[39m=\u001b[39m[]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ahsan/OneDrive/Desktop/ProjectGaze/documentation/DATA.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Here we are first cleaning some of the names that we have. We might have some apostraphe or capital small or decimals at \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ahsan/OneDrive/Desktop/ProjectGaze/documentation/DATA.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# beginning or end of the word which we want to clean. Then we will be using a python library called gender guesser which\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ahsan/OneDrive/Desktop/ProjectGaze/documentation/DATA.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# takes a name and then assignes the gender. it is either male, female, mostly male, mostly female, androgynous.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gender' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "d = gender.Detector(case_sensitive=False)\n",
    "data=[]\n",
    "\n",
    "# Here we are first cleaning some of the names that we have. We might have some apostraphe or capital small or decimals at \n",
    "# beginning or end of the word which we want to clean. Then we will be using a python library called gender guesser which\n",
    "# takes a name and then assignes the gender. it is either male, female, mostly male, mostly female, androgynous.\n",
    "\n",
    "\n",
    "for key,value in js.items():\n",
    "#     if key == 'titanic-numbered.pdf':\n",
    "    print(\"-----------------\"+key+\"-----------------------\")\n",
    "#     data.append([key,'','',''])\n",
    "    #     Sorted = sorted(value, key=lambda k: len(d[k]), reverse=True)\n",
    "    for k in sorted(value, key=lambda k: len(value[k]), reverse=True):\n",
    "        if len(value[k])>=10 and len(k)>=2:\n",
    "            name = k.split(\" \")[0]\n",
    "            name  = re.sub(r'\\'\\w+', '', name)\n",
    "            name  = re.sub(r'\\-\\w+', '', name)\n",
    "            name  = re.sub(r'\\:','', name)\n",
    "            name  = re.sub(r'\\.','', name)\n",
    "            name  = re.sub(r'(CONT)','', name)\n",
    "            name  = re.sub(r'','', name)\n",
    "            name = name.strip(\"()\")\n",
    "            name = name.strip('\"')\n",
    "            print([key,k,name,\"m\",len(value[k])])\n",
    "            \n",
    "            if d.get_gender(name) == \"male\":\n",
    "                data.append([key,k,name,\"m\",len(value[k])])\n",
    "            elif d.get_gender(name) == \"female\":\n",
    "                data.append([key,k,name,\"f\",len(value[k])])\n",
    "            elif d.get_gender(name) == \"mostly_male\":\n",
    "                data.append([key,k,name,\"m\",len(value[k])])\n",
    "            elif d.get_gender(name) == \"mostly_female\":\n",
    "                data.append([key,k,name,\"f\",len(value[k])])\n",
    "            elif d.get_gender(name) == \"andy\":\n",
    "                data.append([key,k,name,\"m\",len(value[k])])\n",
    "            else:\n",
    "                data.append([key,k,name,\"u\",len(value[k])])\n",
    "            \n",
    "            \n",
    "#             print (k,len(value[k]),d.get_gender(k.split(' ')[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the male and non male characters which are saved in a csv file, we simply get the sum of all the male and non male characters dialogue length that was detected for each of the scripts. This helps us understand the distribution of the dialogues between the two categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "header = ['movie','name from script', 'lemmatized name','gender', 'len of words']\n",
    "\n",
    "# Here we save all the results in an excel file and manually fix for the names that could not be populated.\n",
    "\n",
    "with open('char.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # write multiple rows\n",
    "    writer.writerows(data)\n",
    "\n",
    "# read by default 1st sheet of an excel file\n",
    "df = pd.read_excel('char.xlsx')\n",
    "\n",
    "# After reading from the excel we group by on the basis of the movie to get the sum of male and female characters.\n",
    "df2 = df.groupby(['movie','gender'])['len of words'].sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# movies={}\n",
    "\n",
    "    \n",
    "#     dic={}\n",
    "#     if row['movie'] not in movies:\n",
    "#         movies[row['movie']]\n",
    "#     else:\n",
    "#         print(row['movie'], row['name from script'],row[\"lemmatized name\"],row[\"gender\"],row[\"len of words\"])\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddic={}\n",
    "for index, row in df2.iterrows():\n",
    "#     lst=[]\n",
    "    if row['movie'] not in ddic:\n",
    "        if row['gender'] == \"m\":\n",
    "            ddic[row[\"movie\"]]=[('m',row['len of words'])]\n",
    "        elif row['gender'] == \"f\":\n",
    "            ddic[row[\"movie\"]]=[('f',row['len of words'])]\n",
    "    else:\n",
    "        if row['gender'] == \"m\":\n",
    "#             print(m,ddic[row['movie']])\n",
    "            ddic[row[\"movie\"]].append(('m',row['len of words']))\n",
    "        elif row['gender'] == \"f\":\n",
    "#             print(m,ddic[row['movie']])\n",
    "            ddic[row[\"movie\"]].append(('f',row['len of words']))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ddic)\n",
    "lss1 =[]\n",
    "lss2 = []\n",
    "lss3 = []\n",
    "lss4 = []\n",
    "\n",
    "# Here we are able to make a dataframe of male and female dialogue divisions for each movie\n",
    "for key in ddic:\n",
    "    if len(ddic[key])>1:\n",
    "        print(key,ddic[key])\n",
    "        lss1.append(key)\n",
    "        if ddic[key][0][0]=='m':\n",
    "            lss2.append(ddic[key][0][1])\n",
    "        if ddic[key][0][0]=='f':\n",
    "            lss3.append(ddic[key][0][1])\n",
    "        if ddic[key][1][0]=='m':\n",
    "            lss2.append(ddic[key][1][1])\n",
    "        if ddic[key][1][0]=='f':\n",
    "            lss3.append(ddic[key][1][1])\n",
    "            \n",
    "            \n",
    "            \n",
    "df_f = pd.DataFrame(list(zip(lss1,lss2,lss3)),\n",
    "               columns =['Name', 'm','f'])\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f[\"total\"] = df_f[\"m\"] + df_f[\"f\"]\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the percentage of male dialogue from total\n",
    "df_f[\"male_percen\"] = (df_f[\"m\"] / df_f[\"total\"])*100\n",
    "df_f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once we have the male percentages, we can get the total and non-male percentages as well. Then we join them with all the movies dataframe which is saved in another csv to combine all our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.read_csv('../Data/bechdel/all_movies_bechdel.csv')\n",
    "# !pip install difflib\n",
    "\n",
    "# Here we are using a library difflib which will allow us to get the actual names of the movies from the dataset already prepared\n",
    "\n",
    "dd_1 = df_m['Title'].to_list()\n",
    "dd_2= df_f['Name'].to_list()\n",
    "dd_3 = df_f['male_percen'].to_list()\n",
    "dd_4=[]\n",
    "for i in dd_2:\n",
    "    dd_4.append(difflib.get_close_matches(i, dd_1, len(dd_1), 0)[0])\n",
    "#     print(i,difflib.get_close_matches(i, dd_1, len(dd_1), 0)[0])\n",
    "\n",
    "df_5 = pd.DataFrame(list(zip(dd_2,dd_4,dd_3)),\n",
    "               columns =['script_name', 'movie_name','male_percen'])\n",
    "df_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Final \"Gaze Score\"\n",
    "In this step we will be developing a mechanism in order to **assign a score to each film** within our scope. This scoring is important for us as we take into account all the factors analyzed above and assign a score from a **range of 0-100**.\n",
    "\n",
    "The divisiion of the score is as follows:\n",
    "1. **Bechdel Test** (max. 40%), score assigned based on the following criteria\n",
    "    1. If a movie passes **no rule**: 40%\n",
    "    2. If a movie passes **only the first rule**: 26.66%\n",
    "    3. If a movie passes **only the first and second rules**: 13.33%\n",
    "    4. If a movie passes **all rules**: 0%\n",
    "2. **Character description** (max. 35%), score assigned based on the following criteria\n",
    "    1. If a female character's body is described **more than the observed average**: the percentage is assigned according to the number of occurences, with a maximum value of 30%\n",
    "    2. If a female character is described in a **dubious, problematic or sexist** manner: the score's calculation is more sensitive to these occurences and the percentage is assigned accordingly, with a maximum value of 35%\n",
    "    3. If a female character is not particularly described in any of the above manners: 0%\n",
    "3. **Character dialogues** (max. 25%), score assigned based on the following criteria:\n",
    "    1. If a male character has less than or equal to 50% of the overrall dialogue in the script: 0%\n",
    "    2. If a male character has more than or equal to 70% of the overall dialogue in the script: 25%\n",
    "    3. If a male character has dialogue between 51% to 69% of the overall dialogue in the script: the percentage will be assigned on the basis of the percentile between values 0.1%-24.9%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final.to_csv('dialogue_score.csv')\n",
    "bechdel = pd.read_csv('../Data/bechdel/all_movies_bechdel.csv')\n",
    "male = pd.read_csv('dialogue_score.csv')\n",
    "fin=pd.merge(bechdel,male, left_on='Title', right_on='movie_name', how='left')\n",
    "\n",
    "def categorise(row):  \n",
    "    if row['bechdel_rating'] == 0.0:\n",
    "        return 40\n",
    "    elif row['bechdel_rating'] == 1.0:\n",
    "        return 26.66\n",
    "    elif row['bechdel_rating'] == 2.0:\n",
    "        return 13.33\n",
    "    elif row['bechdel_rating'] == 3.0:\n",
    "        return 0\n",
    "    \n",
    "fin['bechdel_score'] = fin.apply(lambda row: categorise(row), axis=1)\n",
    "\n",
    "fin.to_csv('dialogue_bechdel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p>For assigning a score based on the type of character descriptions, we will be using the dataframe containing all the counts of body descriptions and dubious words for each film. We chose not to penalize films that contain just under the average amount of simple body descriptions, taking into consideration that film scripts will inadvertedly contain such descriptions.</p>\n",
    "\n",
    "<p> The following function assigns a score to each film according to its number of body occurences, and it more sensitive to the dubious values, if they are found.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vals = fem_desc_graph['count'].to_list()\n",
    "inapp_vals = fem_desc_graph['inappropriate_count'].to_list()\n",
    "\n",
    "# calculate the mean value of the sum of the values\n",
    "mean_val =  sum(vals)/len(vals) #average amount of body descriptions\n",
    "\n",
    "# calculate the percentile for the maximum value\n",
    "max_val = max(vals)\n",
    "max_percentile = 35 #our max value for the characters' description category\n",
    "\n",
    "# create a dictionary mapping each value to its percentile\n",
    "score = []\n",
    "\n",
    "for i, val in enumerate(vals):\n",
    "    if val < mean_val:\n",
    "        film_score = 0\n",
    "    else:\n",
    "        film_score = ((val-mean_val)/(max_val-mean_val))*30 + 1\n",
    "    if inapp_vals[i] > 0:\n",
    "        sigmoid_val = 1 / (1 + np.exp(-(inapp_vals[i] - 2.5) / 2))  # adjust the 2.5 parameter to adjust the sensitivity\n",
    "        inapp_score = sigmoid_val * 10\n",
    "        film_score += inapp_score\n",
    "    score.append(min(film_score, max_percentile))\n",
    "\n",
    "fem_desc_graph['score'] = score\n",
    "\n",
    "fem_desc_graph.drop(columns=['script_name'], inplace=True)\n",
    "fem_desc_graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the mathematical model presented above, we assign the dialogue scores accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.to_csv('male_percen.csv')\n",
    "final = pd.read_csv('male_percen.csv')\n",
    "score=[]\n",
    "l = final['male_percen'].to_list()\n",
    "\n",
    "# Here we are assigning a score for the male percentages of dialogues. \n",
    "# If a male character has less than or equal to 50% of the overall dialougue in the script: 0%\n",
    "# If a male character has more than or equal to 70% of the overall dialougue in the script: 25%\n",
    "# If a male character has dialogue between 51% to 69% of the overall dialougue in the script then the percentage \n",
    "# will be assigned on the basis of the percentile between the values: 0.1%-24.9%\n",
    "\n",
    "for i in l:\n",
    "    if i >= 70:\n",
    "        print(i,25)\n",
    "        score.append(25)\n",
    "    elif i <=50:\n",
    "        print(i,0)\n",
    "        score.append(0)\n",
    "    elif i > 50 and i < 70:\n",
    "        s = (i-50/(70-50))*0.25\n",
    "        ss = (i-50)*1.25\n",
    "        print(i,s,ss)\n",
    "        score.append(ss)\n",
    "        \n",
    "        \n",
    "final['score'] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we proceed with creating a <b>final dataframe</b> containing all of the data retrieved from our scripts analysis and the movies' details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge final results to get the score\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path =\"/\".join(list(cwd.split('/')[0:-1])) \n",
    "\n",
    "df_bechdel_dialogue = pd.read_csv(path+ '/Data/Dialogue/dialogue_bechdel.csv')\n",
    "df_descriptions= pd.read_csv(path+ \"/Data/Descriptions/female_descriptions.csv\")\n",
    "\n",
    "final_scores = pd.merge(df_bechdel_dialogue,df_descriptions, left_on='Title',right_on=\"movie\",how='outer',indicator='_merge')\n",
    "\n",
    "final_scores = final_scores[['imdbid','Title','Decade','Genre','Director','year','bechdel_rating','male_percen',\n",
    "                            'nonmale_percentage','dialogue_score','bechdel_score','count','inappropriate_count','score','_merge']]\n",
    "final_scores.rename(columns={'score':'descriptions_score'},inplace=True)\n",
    "                    \n",
    "final_scores.drop_duplicates(inplace=True)\n",
    "                    \n",
    "final_scores\n",
    "\n",
    "scores_to_count = final_scores[['dialogue_score','bechdel_score','descriptions_score']]\n",
    "\n",
    "final_scores['gaze_score'] = scores_to_count.sum(axis=1)\n",
    "final_scores.drop_duplicates(subset=['Title'], inplace=True)\n",
    "final_scores.drop(columns=['_merge'], inplace=True)\n",
    "final_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The camera: SPARQL metadata retrieval\n",
    "\n",
    "Finally, after gathering some preliminary results from the first analyses on film scripts and IMDB's reviews, we further deepened our research using [**Wikidata**](https://www.wikidata.org/wiki/Wikidata:Main_Page) and its **SPARQL endpoint**.\n",
    "\n",
    "While we had found another interesting database with a SPARQL endpoint, the [**Linked Internet Movie Database (IMDb)**](https://triplydb.com/Triply/linkedmdb), and proceeded with an initial phase of **data exploration** (as it was an unknown), we quickly found out that it was missing some of more relevant information for the scope of our project, such as the gender of people working on the movie (e.g. directors, writers...). Moreover, the \"imdb id\" it presented was actually different than the one on Wikidata, which, on the other hand, had all the necessary information.\n",
    "\n",
    "The SPARQL queries are based on the results coming from the [script analysis](###The-characters:-film-and-scripts-analysis) and [review analysis](##The-audience:-webscraping,-sentiment-and-sexism) (respectively, the \"characters\" and \"audience\" sections):,\n",
    "- The audience results,\n",
    "    - Sentiment analysis: 10 out of 80 audiences expressed a very negative opinion of the movie they watched\n",
    "    - Sexism detection: 17 movies had a sexist audience, but instances of such behaviour were rare and sporadic if considered over the total number of reviews for each movie\n",
    "    - Overall, we found no direct link between an audience's sexism and the reviews' tone.\n",
    "- The characters results,\n",
    "    - Bechdel test: out of the 82 films what were evaluated:\n",
    "        - 38 films passed the Bechdel test\n",
    "        - 5 failed all rules\n",
    "        - 20 failed the second and third rule\n",
    "        - 9 failed the third rule\n",
    "    - Character dialogue analysis: out of all the scripts that we were able to retreive:\n",
    "        - 94% of the scripts were male dominated (more than 50% dialogues)\n",
    "        - 6% scripts had non male dialogues in majority\n",
    "    - Gaze score: We were successfully able to assign an arbitrary value between 0-100 to each of the films under our research. This score will help us understand gaze and will help us compare it to other variables.\n",
    "\n",
    "Queries:\n",
    "1. The \"characters\" queries:\n",
    "    1. Bechdel test: *how many of the [selected] films have **male** directors?*\n",
    "    2. Character dialogue: *what is the proportion between male and female writers in the [selected] films?*\n",
    "2. Gaze score queries:\n",
    "    1. *To what genre belong the top 10 films in the gaze score ranking?*\n",
    "    2. *Is there any correlation between rank in the gaze score ranking, box-office and production costs?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The \"Characters\" queries\n",
    "##### Bechdel test query: *how many of the [selected and tested for Bechdel] movies have **male** directors?*\n",
    "To answer this query (and the following one, regarding character dialogues) we gather data from the `dialogue_bechdel.csv` file.\n",
    "\n",
    "We first **read the CSV file as a dataframe and clean it**, dropping all the movies which have not been tested for the Bechdel test: these movies will have a `NaN` value under the `bechdel_rating` column.\n",
    "\n",
    "We then create an **empty list `film_list_bechdel`**, containing tuples representing the IMDB id of the movie (`imdbid` column) and its result in the Bechdel test (column `bechdel_rating`).\n",
    "If the `bechdel_rating` is...:\n",
    "- 0 &rarr; FAILED the first criteria\n",
    "- 1 &rarr; FAILED the second criteria\n",
    "- 2 &rarr; FAILED the third criteria\n",
    "- 3 &rarr; PASSED the test (passed all three criteria) \n",
    "\n",
    "As our starting IMDB's ids are actually different than those present in wikipedia (which have a suffix differentiating between titles, names, companies, events, news...), before populating the `film_list_bechdel` we need to process the ids and add the suffix.\n",
    "\n",
    "We do so with the appropriate function `createIMDBid`.\n",
    "\n",
    "Then, we populate the `film_list_bechdel` and measure its length: this is the total number of movies which have been tested for the Bechdel test (72)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of movies tested for Bechdel test:\t 72\n"
     ]
    }
   ],
   "source": [
    "import sparql_dataframe\n",
    "\n",
    "wikidata_endpoint = \"https://query.wikidata.org/bigdata/namespace/wdq/sparql\"\n",
    "\n",
    "df = pd.read_csv('../data/dialogue/dialogue_bechdel.csv')\n",
    "\n",
    "def createIMDBid(code):\n",
    "    if len(str(code)) == 5:\n",
    "        return \"tt00\"+str(code)\n",
    "    elif len(str(code)) == 6:\n",
    "        return \"tt0\"+str(code)\n",
    "    elif len(str(code)) == 7:\n",
    "        return \"tt\"+str(code)\n",
    "\n",
    "bechdel_df = df.dropna(axis=0, subset=[\"bechdel_rating\"])\n",
    "\n",
    "film_list_bechdel = list()\n",
    "\n",
    "for idx, row in bechdel_df.iterrows():\n",
    "    imdb_id = createIMDBid(row[\"imdbid\"])\n",
    "    tuple = (imdb_id, row[\"bechdel_rating\"])\n",
    "    film_list_bechdel.append(tuple)\n",
    "\n",
    "n_films_B = len(film_list_bechdel)    # 72\n",
    "print(\"Total number of movies tested for Bechdel test:\\t\",n_films_B)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We create a `ids_tpl_bechdel` tuple (to be used in the SPARQL query) containing only the formatted IMDB's ids taken from the `film_list_bechdel`.\n",
    "\n",
    "Finally, we query the SPARQL endpoint, selecting only the movies from our list which have a **male director** (specified by the Wikidata class `wd:Q6581097`).\n",
    "\n",
    "We use the `FILTER` and `IN` clauses to run the query on all the IMDB's ids contained in our list without having to open the query connection multiple times (as experienced, that will overwork Wikidata's query service and the IP of the computer used to run the query will be momentarily banned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_tpl_bechdel = ()\n",
    "\n",
    "for tpl in film_list_bechdel:\n",
    "    ids_tpl_bechdel = ids_tpl_bechdel + (tpl[0],)\n",
    "\n",
    "# SPARQL\n",
    "query_gender_director = '''\n",
    "        SELECT ?imdb ?Movie ?Director\n",
    "        WHERE {{\n",
    "            ?movie wdt:P345 ?imdb ;\n",
    "                    wdt:P57 ?director ;\n",
    "                    rdfs:label ?Movie .\n",
    "            ?director rdfs:label ?Director ;\n",
    "                        wdt:P21 wd:Q6581097 .\n",
    "            FILTER ((lang(?Director) = \"en\") && (lang(?Movie) = \"en\")) .\n",
    "            FILTER (?imdb IN {list}) .\n",
    "        }}\n",
    "    '''\n",
    "\n",
    "result_bechdel_query = sparql_dataframe.get(\n",
    "    wikidata_endpoint, query_gender_director.format(list=ids_tpl_bechdel), True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we want to add the outcome of the Bechdel test of the result of the query, we create another dataframe `add_bech_df` from the list of tuples `film_list_bechdel` (in which the first element of each tuple is the formatted IMDB's id, and the second element is the outcome of the Bechdel test).\n",
    "\n",
    "We then merge the two dataframes `result_bechdel_query` and `add_bech_df` together, using the `imdb` column as merging point.\n",
    "\n",
    "Now, if we count the number of rows of the updated `result_bechdel_query`, we will have the **total number of male directors of the movies tested for the Bechdel test**.\n",
    "Please notice how this number is actually higher than the total number of movies tested for the Bechdel test (`n_films_B`): this is because some movies will have more than one director.\n",
    "\n",
    "The result of this query means that **no matter the result of the Bechdel test, all the movies which have been tested for it have male directors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of movies tested for Bechdel test WITH male director(s):\t 79\n"
     ]
    }
   ],
   "source": [
    "add_bech_df = pd.DataFrame(film_list_bechdel, columns=[\n",
    "                           \"imdb\", \"Bechdel_result\"])\n",
    "\n",
    "result_bechdel_query = result_bechdel_query.merge(\n",
    "    add_bech_df, left_on=\"imdb\", right_on=\"imdb\")\n",
    "\n",
    "\n",
    "total_Mdirectors = (len(result_bechdel_query.index))  # 79\n",
    "print(\"Total number of movies tested for Bechdel test WITH male director(s):\\t\",total_Mdirectors)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Characters dialogue query: *how many of the [selected] films have **male** directors?*\n",
    "\n",
    "Even for this query we are using the data from the `dialogue_bechdel.csv` file.\n",
    "\n",
    "The reasoning behind this query is more or less the same as the previous one:\n",
    "1. **Read the CSV file as a dataframe and clean it** from all the movies that have no dialogue analysis (using the `.dropna` instruction, as they will have a `NaN` value under the `male_percen` column)\n",
    "2. Create a **`film_list_dlg` of tuples containing the IMDB id of the movie** (`imdbid` column) and the **information on the dialogues** (`male_percen` and `nonmale_percentage` columns); then, measure its length: this is the total number of movies which have dialogue analysis\n",
    "3. Use the previously defined `createIMDBid` function to add the Wikidata's suffix to our starting IMDB's ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of movies with a dialogue analysis:\t 66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "film_list_dlg = list()\n",
    "\n",
    "dlg_df = df.dropna(axis=0, subset=[\"male_percen\"])\n",
    "\n",
    "for idx, row in dlg_df.iterrows():\n",
    "    imdb_id = createIMDBid(row[\"imdbid\"])\n",
    "    tuple = (imdb_id, row[\"male_percen\"], row[\"nonmale_percentage\"])\n",
    "    film_list_dlg.append(tuple)\n",
    "\n",
    "n_films = len(film_list_dlg)    # 66\n",
    "print(\"Total number of movies with a dialogue analysis:\\t\",n_films)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the `ids_tpl_dlg` tuple with only the formatted IMDB's ids (taken from the `film_list_dlg`)\n",
    "5. Query the SPARQL endpoint selecting **the writers for each movie (regardless of their gender) and their gender** \"value\"\n",
    "    - The use of the `OPTIONAL` clause was necessary as it seems not all writers have the gender information available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Orsola\\Documents\\GitHub\\ProjectGaze\\documentation\\DATA.ipynb Cell 56\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#Y115sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# SPARQL\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#Y115sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m query_gender_director \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#Y115sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m    SELECT ?imdb ?Movie ?Writer ?Gender\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#Y115sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m    WHERE \u001b[39m\u001b[39m{{\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#Y115sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m}}\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#Y115sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m'''\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#Y115sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m result_dlg_query \u001b[39m=\u001b[39m sparql_dataframe\u001b[39m.\u001b[39;49mget(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#Y115sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     wikidata_endpoint, query_gender_director\u001b[39m.\u001b[39;49mformat(\u001b[39mlist\u001b[39;49m\u001b[39m=\u001b[39;49mids_tpl_dlg), \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#Y115sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m result_dlg_query\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sparql_dataframe\\sparql_dataframe.py:29\u001b[0m, in \u001b[0;36mget_sparql_dataframe\u001b[1;34m(endpoint, query, post)\u001b[0m\n\u001b[0;32m     26\u001b[0m     sparql\u001b[39m.\u001b[39msetRequestMethod(POSTDIRECTLY)\n\u001b[0;32m     28\u001b[0m sparql\u001b[39m.\u001b[39msetReturnFormat(CSV)\n\u001b[1;32m---> 29\u001b[0m results \u001b[39m=\u001b[39m sparql\u001b[39m.\u001b[39;49mquery()\u001b[39m.\u001b[39mconvert()\n\u001b[0;32m     30\u001b[0m _csv \u001b[39m=\u001b[39m StringIO(results\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(_csv, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\SPARQLWrapper\\Wrapper.py:960\u001b[0m, in \u001b[0;36mSPARQLWrapper.query\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mQueryResult\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    943\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[39m    Execute the query.\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[39m    Exceptions can be raised if either the URI is wrong or the HTTP sends back an error (this is also the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[39m    :rtype: :class:`QueryResult` instance\u001b[39;00m\n\u001b[0;32m    959\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 960\u001b[0m     \u001b[39mreturn\u001b[39;00m QueryResult(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query())\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\SPARQLWrapper\\Wrapper.py:926\u001b[0m, in \u001b[0;36mSPARQLWrapper._query\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    924\u001b[0m         response \u001b[39m=\u001b[39m urlopener(request, timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout)\n\u001b[0;32m    925\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m         response \u001b[39m=\u001b[39m urlopener(request)\n\u001b[0;32m    927\u001b[0m     \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturnFormat\n\u001b[0;32m    928\u001b[0m \u001b[39mexcept\u001b[39;00m urllib\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[0;32m    537\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[0;32m    538\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1352\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[1;32m-> 1352\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m   1353\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m   1354\u001b[0m     h\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1368\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1367\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1369\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1370\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:317\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    319\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:278\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 278\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    279\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    280\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1269\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1270\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1271\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1272\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1273\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1275\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1128\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1129\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1130\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ids_tpl_dlg = ()\n",
    "\n",
    "for tpl in film_list_dlg:\n",
    "    ids_tpl_dlg = ids_tpl_dlg + (tpl[0],)\n",
    "\n",
    "# SPARQL\n",
    "query_gender_director = '''\n",
    "    SELECT ?imdb ?Movie ?Writer ?Gender\n",
    "    WHERE {{\n",
    "        ?movie wdt:P345 ?imdb ;\n",
    "                wdt:P58 ?writer ;\n",
    "                rdfs:label ?Movie .\n",
    "        ?writer rdfs:label ?Writer .\n",
    "        OPTIONAL {{\n",
    "            ?writer wdt:P21 ?gender .\n",
    "            ?gender rdfs:label ?Gender .\n",
    "            FILTER ( (lang(?Gender) = \"en\") )\n",
    "        }}\n",
    "        FILTER ( (lang(?Writer) = \"en\") && (lang(?Movie) = \"en\"))\n",
    "        FILTER ( ?imdb IN {list} )\n",
    "}}\n",
    "'''\n",
    "\n",
    "result_dlg_query = sparql_dataframe.get(\n",
    "    wikidata_endpoint, query_gender_director.format(list=ids_tpl_dlg), True)\n",
    "result_dlg_query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Add the outcome of the dialogue analysis through a new dataframe `add_dlg_df`, created from the list of tuples `film_list_dlg`\n",
    "7. Merge the two dataframes `result_dlg_query` and `add_dlg_df`\n",
    "8. Save the dataframe in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_dlg_df = pd.DataFrame(film_list_dlg, columns=[\n",
    "                           \"imdb\", \"male_percentage\", \"nonmale_percentage\"])\n",
    "\n",
    "# Merge the two dataframes together using the IMDB ids columns\n",
    "result_dlg_query = result_dlg_query.merge(\n",
    "    add_dlg_df, left_on=\"imdb\", right_on=\"imdb\")\n",
    "\n",
    "result_dlg_query\n",
    "# result_dlg_query.to_csv('data/sparql/dlg.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can quickly compare the number of male and female writers in our selection of the movies. We do so by simply iterating through the `result_dlg_query` dataframe and update the number of writers (either `n_Mwriters` or `n_Fwriters`) depending on the value under the column `Gender`. We also print out the total number of writers in our 66 selected movies.\n",
    "\n",
    "The difference is clear and pretty straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_writers = (len(result_dlg_query.index))\n",
    "print(\"Total number of writers of the selected 66 movies:\\t\",n_writers) # 154\n",
    "\n",
    "\n",
    "n_Mwriters = 0\n",
    "n_Fwriters = 0\n",
    "for idx, row in result_dlg_query.iterrows():\n",
    "    if row[\"Gender\"] == 'male':\n",
    "        n_Mwriters += 1\n",
    "    else:\n",
    "        n_Fwriters += 1\n",
    "\n",
    "print(\"Number of male writers\\t:\", n_Mwriters)  # 143\n",
    "print(\"Number of female writers\\t:\", n_Fwriters)    # 11\n",
    "\n",
    "# result_dlg_query.to_csv('data/sparql/dlg.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaze score queries\n",
    "\n",
    "For these queries, the data used comes from the `final_scores_df.csv` CSV file.\n",
    "Again, even in this case the reasoning is always the same as before.\n",
    "\n",
    "\n",
    "##### GS query 1: *To what genre belong the top 10 films in the gaze score ranking?*\n",
    "\n",
    "1. **Read the CSV file as a dataframe and clean it** from all the movies that have no male gaze score (using the `.dropna` instruction, as they will have a `NaN` value under the `gaze_score` column); then, **sort it** depending on the male gaze value (`MG_df`) and then **select only the top 10 movies** (`topMG_df`)\n",
    "2. Create a **`film_list_mg1` of tuples containing the IMDB id of the movie** (`imdbid` column) and the **male gaze score** (`gaze_score` column); then, measure its length: this is the total number of movies which have a male gaze score\n",
    "3. Use the previously defined `createIMDBid` function to add the Wikidata's suffix to our starting IMDB's ids\n",
    "4. Create the `ids_tpl_mg1` tuple with only the formatted IMDB's ids (taken from the `film_list_mg1`)\n",
    "5. Query the SPARQL endpoint selecting **the genres for each movie** of the movies in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mg = pd.read_csv('../data/final_scores/final_scores_df.csv')\n",
    "\n",
    "MG_df = df_mg.dropna(axis=0, subset=[\"gaze_score\"])\n",
    "\n",
    "MG_df.sort_values(by=\"gaze_score\", ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "topMG_df = MG_df.head(10)\n",
    "\n",
    "\n",
    "film_list_mg1 = list()\n",
    "\n",
    "for idx, row in topMG_df.iterrows():\n",
    "    imdb_id = createIMDBid(row[\"imdbid\"])\n",
    "    tuple = (imdb_id, row[\"gaze_score\"])\n",
    "    film_list_mg1.append(tuple)\n",
    "\n",
    "print(\"Top 10 movies of the male gaze score ranking:\\t\",len(film_list_mg1))\n",
    "\n",
    "ids_tpl_mg1 = ()\n",
    "\n",
    "for tpl in film_list_mg1:\n",
    "    ids_tpl_mg1 = ids_tpl_mg1 + (tpl[0],)\n",
    "\n",
    "# SPARQL\n",
    "query_10_mg = '''\n",
    "    SELECT ?imdb ?Movie ?Genre\n",
    "    WHERE {{\n",
    "        ?movie wdt:P345 ?imdb ;\n",
    "                wdt:P136 ?genre ;\n",
    "                rdfs:label ?Movie .\n",
    "        ?genre rdfs:label ?Genre .\n",
    "        FILTER ( (lang(?Movie) = \"en\") && (lang(?Genre) = \"en\"))\n",
    "        FILTER ( ?imdb IN {list} )\n",
    "    }}\n",
    "'''\n",
    "\n",
    "result_mg1_query = sparql_dataframe.get(wikidata_endpoint, query_10_mg.format(list=ids_tpl_mg1),True)\n",
    "#result_mg1_query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Add the male gaze score through a new dataframe `add_mg1_df`, created from the list of tuples `film_list_mg1`\n",
    "7. Merge the two dataframes `result_mg1_query` and `add_mg1_df`\n",
    "8. Save the dataframe in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_mg1_df = pd.DataFrame(film_list_mg1,columns=[\"imdb\", \"gaze_score\"])\n",
    "\n",
    "result_mg1_query = result_mg1_query.merge(add_mg1_df,left_on=\"imdb\",right_on=\"imdb\")\n",
    "# result_mg1_query.to_csv('../data/sparql/mg1.csv')\n",
    "print(result_mg1_query.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GS query 2: *Is there any correlation between rank in the gaze score ranking, box-office and production costs?*\n",
    "\n",
    "1. Use the `MG_df` already cleaned and sorted from before\n",
    "2. Create a **`film_list_mg2` of tuples containing the IMDB id of the movie** (`imdbid` column) and the **male gaze score** (`gaze_score` column); then, measure its length: this is the total number of movies which have a male gaze score\n",
    "3. Use the previously defined `createIMDBid` function to add the Wikidata's suffix to our starting IMDB's ids\n",
    "4. Create the `ids_tpl_mg2` tuple with only the formatted IMDB's ids (taken from the `film_list_mg2`)\n",
    "5. Query the SPARQL endpoint selecting **the production costs and the box office** of the movies in the list\n",
    "    - Again, the `OPTIONAL` clauses were necessary for the lack of information regarding production costs and box office for some of the movies in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_list_mg2 = list()\n",
    "\n",
    "for idx, row in MG_df.iterrows():\n",
    "    imdb_id = createIMDBid(row[\"imdbid\"])\n",
    "    tuple = (imdb_id, row[\"gaze_score\"])\n",
    "    film_list_mg2.append(tuple)\n",
    "\n",
    "print(\"Total number of movies with a male gaze score:\\t\",len(film_list_mg2))\n",
    "\n",
    "ids_tpl_mg2 = ()\n",
    "\n",
    "for tpl in film_list_mg2:\n",
    "    ids_tpl_mg2 = ids_tpl_mg2 + (tpl[0],)\n",
    "\n",
    "\n",
    "# SPARQL\n",
    "query_costs_mg = '''\n",
    "SELECT ?imdb ?Movie ?ProductionCosts ?BoxOffice \n",
    "WHERE {{\n",
    "  ?movie wdt:P345 ?imdb ;\n",
    "        rdfs:label ?Movie .\n",
    "  OPTIONAL {{\n",
    "    ?movie wdt:P2130 ?ProductionCosts .\n",
    "  }}\n",
    "  OPTIONAL {{\n",
    "    ?movie wdt:P2142 ?BoxOffice .\n",
    "    ?statement ps:P2142 ?BoxOffice .\n",
    "    ?statement pq:P3005 ?validity .\n",
    "    }}\n",
    "  FILTER ( (lang(?Movie) = \"en\") && ((?validity = wd:Q30) || (?validity = wd:Q49)) )\n",
    "  FILTER NOT EXISTS {{ ?statement pq:P1264 ?o }}\n",
    "  FILTER ( ?imdb in {list} )\n",
    "}}\n",
    "'''\n",
    "\n",
    "result_mg2_query = sparql_dataframe.get(wikidata_endpoint, query_costs_mg.format(list=ids_tpl_mg2),True)\n",
    "result_mg2_query.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Add the male gaze score through a new dataframe `add_mg2_df`, created from the list of tuples `film_list_mg2`\n",
    "7. Merge the two dataframes `result_mg2_query` and `add_mg2_df`\n",
    "8. Save the dataframe in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_mg2_df = pd.DataFrame(film_list_mg2,columns=[\"imdb\", \"gaze_score\"])\n",
    "\n",
    "result_mg2_query = result_mg2_query.merge(add_mg2_df,left_on=\"imdb\",right_on=\"imdb\")\n",
    "result_mg2_query\n",
    "\n",
    "# result_mg2_query.to_csv('../data/sparql/mg2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
