{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Through the Gaze - Data documentation\n",
    "This Jupyter Notebook analyses the data preparation and processing phase for [\"NameProject\"](https://ahsanv101.github.io/ProjectGaze/).\n",
    "\n",
    "For this project, we are interested in studying the concept of the **\"male gaze\"** in cinema, inspired by the essay \"Visual Pleasure and Narrative Cinema\" by the feminist film theorist Laura Mulvey. Mulvey underlines how the \"male gaze\" is made of three main components:\n",
    "1. The audience\n",
    "2. The characters\n",
    "3. The camera (i.e. the director)\n",
    "\n",
    "To represent a coherent and significant overview on the male gaze's impact on western cinematic industry, we will identify the **10 highest-grossing U.S. films for each decade from 1940s to 2010s**. The reason to opt for highest-grossing movies is that they give a general understanding of the popularity of the movie also in terms of fame and profit (highest grossing = surplus amount of people saw it), as well as produce a sort of cultural normativity.\n",
    "Taking highest-grossing movies per decade will help us generalize our results in terms of popularity.\n",
    "\n",
    "\n",
    "### Disclaimer \n",
    "This Jupyter Notebook is of informational nature only, it is not thought to be used for the data preparation and processing, but only for the analysis and explanation of such processes.\n",
    "<br>The Python files used for the clean up can be found in the `code` folder of the [Github repository](https://github.com/ahsanv101/ProjectGaze)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The audience: webscraping, sentiment and sexism\n",
    "Focusing on the audience component of the male gaze implied looking through some of the **reviews** provided for all the movies belonging to our dataset, and focusing not only on the overall reception of the movie, but mostly on the individuals' perception of it and possible gender bias underlying their opinion.\n",
    "\n",
    "\n",
    "Reviews are **not accompanied by the user that provided them**, since that was not useful for our analysis: what is important to keep in mind is that our reviews' dataset comprehends 1972 reviews related to our chosen movies, and that they are completely **public and available on the IMDB's reviews' pages**. Moreover, it's essential to underline that our analysis is partial and neutral, and hopes to elaborate useful reflections more than harsh critiques. \n",
    "\n",
    "### Reviews webscraping\n",
    "The first step of our audience's analysis comprehended a webscraping of the reviews' pages provided in the movie.csv files in URLs form. To do so, we used the [**BeautifulSoup library**](https://www.crummy.com/software/BeautifulSoup/) and we inspected the HTML structure of a standard IMDB's review's page: the textual content of any review is stored inside a `div` block marked by the tag \"text\", and here we access to all of our data. \n",
    "<br>\n",
    "The task, mostly automated, only required a division of the URLS into chunks, to speed up the overall scraping process (since we were working with huge amounts of data!). \n",
    "\n",
    "\n",
    "We later stored our reviews in a dictionary, then turned dataframe, then turned into a **`.csv` file**, containing a unique column, `Reviews`, alongside an index. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'movies.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Orsola\\Documents\\GitHub\\ProjectGaze\\documentation\\DATA.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#Here we initialize and modify our CSVs accordingly and we create a list for the webscraped reviews \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m movies \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mmovies.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m title_reviews \u001b[39m=\u001b[39m movies[[\u001b[39m'\u001b[39m\u001b[39mTitle\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mReviews\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Orsola/Documents/GitHub/ProjectGaze/documentation/DATA.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m text_reviews \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Orsola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'movies.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "#We used the following libraries!\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "#Here we initialize and modify our CSVs accordingly and we create a list for the webscraped reviews \n",
    "movies = pd.read_csv('movies.csv')\n",
    "title_reviews = movies[['Title','Reviews']].copy()\n",
    "\n",
    "text_reviews = []\n",
    "\n",
    "#The webrascraping starts here\n",
    "batch_size = 79\n",
    "urls = ['https://www.imdb.com/title/tt0038969/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0041838/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0031381/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0037536/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0034167/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0036872/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0039391/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0035575/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0034583/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0040806/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0049833/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0045793/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0044672/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0044672/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0047673/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0043949/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0051459/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0053291/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0048593/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0042192/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0059742/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0061722/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0064115/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0058331/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0056937/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0062622/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0055614/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0054215/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0056172/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0060164/?ref_=nv_sr_srsg_3', 'https://www.imdb.com/title/tt0073195/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0076759/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0070047/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0077631/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0068646/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0071230/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0075148/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0066011/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0078346/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0067093/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0080684/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0083866/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0096895/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0086190/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0087332/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0088763/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0092099/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0092644/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0096438/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0081573/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0120338/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0120915/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0107290/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0116629/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0109830/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0119654/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0099653/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0103064/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0103776/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0112462/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0468569/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0383574/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0145487/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0417741/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0121766/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0316654/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0418279/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0325980/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0241527/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0120755/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt4154796/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt1825683/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt2488496/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0848228/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt2527336/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0499549/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt0770828/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt3748528/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt1201607/reviews?ref_=tt_urv', 'https://www.imdb.com/title/tt1877832/reviews?ref_=tt_urv']\n",
    "url_chunks = [urls[x:x+batch_size] for x in range(0, len(urls), batch_size)]\n",
    "\n",
    "def scrape_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for links in soup.find_all('div', class_='text'):\n",
    "            review = links.get_text()\n",
    "            text_reviews.append(review)\n",
    "def scrape_batch(url_chunk):\n",
    "    chunk_resp = []\n",
    "    for url in url_chunk:\n",
    "        chunk_resp.append(scrape_url(url))\n",
    "    return chunk_resp\n",
    "for url_chunk in url_chunks:\n",
    "    scrape_batch(url_chunk)\n",
    "    \n",
    "#From the list, we store our results into a dictionary, to later convert into a new dataframe and CSV. \n",
    "reviews_dict = {'Reviews': text_reviews}\n",
    "text_reviews = pd.DataFrame.from_dict(reviews_dict)\n",
    "text_reviews.to_csv(\"text_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "Now that our reviews were available, it was time to actually start working on our analysis: this second step focused mostly on **retrieving the sentiment of our reviews**: *are they positive or negative?*\n",
    "<br>\n",
    "This aspect was later used to understand if there were any strong correlations among the possible sexist tone of a review and its overall sentiment: for example, *how does a poor opinion on women affect the overall perception of a movie?* *Are negative reviews the most sexist?*\n",
    "\n",
    "\n",
    "To achieve a correct sentiment analysis, we used the [**library `NLTK`**](https://www.nltk.org/) and its **`VADER`**, a rule-based sentiment analyzer in which the terms are generally labeled as per their semantic orientation as either positive or negative. \n",
    "The result of this analysis was a **new dataframe** containing our `Reviews` column, a new `Scores` column (containing non-weighted sentiment analysis scores, divided into negative, neutral and positive values), a `Compound` column (weighted values between 0 and 1) and a `Sentiment` column, that provides a clear label distinguishing Positive reviews (pos) from Negative ones (neg). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "df = pd.read_csv('text_reviews.csv')\n",
    "\n",
    "#Here starts the sentiment analysis \n",
    "df.dropna(inplace=True)\n",
    "empty_objects = []\n",
    "for review in df.itertuples():\n",
    "     if type(review)==str:\n",
    "             if review.isspace():\n",
    "                     empty_objects.append(review)\n",
    "df.drop(empty_objects, inplace=True)\n",
    "\n",
    "#We calculate overall scores, compound value and the sentiment label. \n",
    "df['scores'] = df['Reviews'].apply(lambda Reviews: vader.polarity_scores(Reviews))\n",
    "df['compound'] = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df['sentiment'] = df['compound'].apply(lambda c: 'pos' if c >= 0 else 'neg')\n",
    "\n",
    "#... And then we obtain the CSV\n",
    "df.to_csv('sentiment_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sexism Analysis\n",
    "Having cleared the overall sentiment of our reviews, the final step of our audience's analysis comprehended **detecting possible traces of sexism in the reviews**.\n",
    "<br>\n",
    "To do this, we applied a model created and published by the group NLP-LTU on Hugging Face, the [**BerTweet Large Sexism Detector**](https://huggingface.co/NLP-LTU/bertweet-large-sexism-detector), a classification model for detecting sexism in Tweets or short text paragraphs. As some of our reviews were longer than the model's length limit, a few adjustments were implemented.\n",
    "\n",
    "\n",
    "At the end, we obtained a clear result: our reviews were not sexist or, at least, they were *not completely* sexist.\n",
    "<br>\n",
    "BERT categorized them as lacking any kind of gender bias, but, having inspected the reviews ourselves, we knew this was not true: a few reviews showed clear signs of misogyny and sexism, not just by using offensive words such as \"bitch\" or \"tramp\" when referring to actresses or their characters, but by constantly describing them as sexy and beautiful or by comparing them to animals. \n",
    "BERT simply failed to recognized them because, if considered in a quantified way, those sentences weighted very little in the general structure of the review, that otherwise had a very neutral or even positive tone. \n",
    "What emerged from this analysis, is that **the audience's gaze is rarely guided by pure prejudice or malevolence**: realistically, our reviews displayed sexism in a \"natural\" and subtle way, so subtle that even the sexism-detector model failed to aknowledge them when analysing the bigger picture. \n",
    "\n",
    "However, we were not satisfied with this result: we wanted to isolate these instances of sexism, and to do so, we needed to narrow the detector's scope of analysis. Therefore, we introduced a simpler function capable of dividing any reviews into smaller sentences: by doing this, we could obtain singular scores of sexism and give them more significance. \n",
    "If a review had a singular sexist sentence, was therefore marked as sexist, and sorted into the final CSV accordingly to its final sexist score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this code to work, the libraries Transformers and Torch are needed. \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer,pipeline\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "#We define the model, tokenizer and classifier we are going to use \n",
    "model = AutoModelForSequenceClassification.from_pretrained('NLP-LTU/bertweet-large-sexism-detector')\n",
    "tokenizer = AutoTokenizer.from_pretrained('NLP-LTU/bertweet-large-sexism-detector') \n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "df = pd.read_csv('sentiment_reviews.csv')\n",
    "\n",
    "\n",
    "#This portion of codes generates a prediction of the OVERALL review. According to the tensor size, it proceeds directly with the prediction or it adds an ulterior preprocessing and tokenization phase. \n",
    "import math\n",
    "\n",
    "for item in df['Reviews']: \n",
    "  if (len(item.split())>512):\n",
    "    n=math.ceil(len(item.split())/512)\n",
    "    for i in range(n):\n",
    "        if (i==(n-1)):\n",
    "          safe_item=' '.join(item.split()[i*512::])  \n",
    "        else:\n",
    "          item=' '.join(item.split()[i*512:(i+1)*512])\n",
    "          tokenized = tokenizer.encode(item, padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
    "          prediction = classifier(str(tokenized))\n",
    "          print(prediction, item)\n",
    "          \n",
    "#To work on the individual sentences, we used this instead. \n",
    "\n",
    "reviews = []\n",
    "sentences = []\n",
    "\n",
    "for index, item in df.Reviews.items(): \n",
    "      sentence = item.split('.')      \n",
    "      prediction = classifier(sentence)\n",
    "      sentences.append(sentence)  \n",
    "      reviews.append(prediction)\n",
    "      print([sentence, prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The characters: film and scripts analysis\n",
    "The aim of this analysis is to extract the dominance of the male gaze in the scope of the film and script. This is one of the most important analysis as we also directly dive into the core content of the cinema industry which are the scripts, the basis of any film. The reason we chose scripts is because they address **the whole setting of the characters** as well as **how they are defined on the camera** (viewers) and **how the male character in the script perceives the non-male ones**. They also show what kind of dialogues or actions are assigned to male ones vs non male and give us a good comparative analysis. \n",
    "\n",
    "\n",
    "### Bechdel Test\n",
    "The first step into this analysis is the infamous [Bechdel Test](https://bechdeltest.com/), used for measuring **how women are represented in a given film**. There are generally three rules that a film needs to pass:\n",
    "\n",
    "1. The movie has to have at least two women in it\n",
    "2. The movie has to have at least two women who talk to each other\n",
    "3. The movie has to have at least two women who talk to each other and it is about something other than a man\n",
    "\n",
    "If a movie passes all three of the rules then it passes the Bechdel test. This goes to show a very bare minimum bar that ideally every movie should have. We will collect that data from already <a href= \"https://www.kaggle.com/datasets/alisonyao/movie-bechdel-test-scores\">existing datasets</a> and check the results with the scope of our movies. \n",
    "\n",
    "After importing our datasets and performing string cleaning for merging correctly, we assign the corresponding bechdel test values to our given films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>year</th>\n",
       "      <th>rating</th>\n",
       "      <th>dubious</th>\n",
       "      <th>imdbid</th>\n",
       "      <th>id</th>\n",
       "      <th>submitterid</th>\n",
       "      <th>date</th>\n",
       "      <th>visible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Passage de Venus</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3155794.0</td>\n",
       "      <td>9602.0</td>\n",
       "      <td>18880.0</td>\n",
       "      <td>2021-04-02 20:58:09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>La Rosace Magique</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14495706.0</td>\n",
       "      <td>9804.0</td>\n",
       "      <td>19145.0</td>\n",
       "      <td>2021-05-11 00:11:22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sallie Gardner at a Gallop</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2221420.0</td>\n",
       "      <td>9603.0</td>\n",
       "      <td>18882.0</td>\n",
       "      <td>2021-04-03 02:25:27</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Le singe musicien</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12592084.0</td>\n",
       "      <td>9806.0</td>\n",
       "      <td>19151.0</td>\n",
       "      <td>2021-05-11 23:38:54</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Athlete Swinging a Pick</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7816420.0</td>\n",
       "      <td>9816.0</td>\n",
       "      <td>19162.0</td>\n",
       "      <td>2021-05-13 01:32:14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9368</th>\n",
       "      <td>9368</td>\n",
       "      <td>Love Hard</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10752004.0</td>\n",
       "      <td>10152.0</td>\n",
       "      <td>19735.0</td>\n",
       "      <td>2021-12-05 19:22:20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9369</th>\n",
       "      <td>9369</td>\n",
       "      <td>Cruella</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3228774.0</td>\n",
       "      <td>9861.0</td>\n",
       "      <td>19231.0</td>\n",
       "      <td>2021-06-01 03:16:58</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9370</th>\n",
       "      <td>9370</td>\n",
       "      <td>West Side Story</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3581652.0</td>\n",
       "      <td>10157.0</td>\n",
       "      <td>19743.0</td>\n",
       "      <td>2021-12-10 03:10:09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371</th>\n",
       "      <td>9371</td>\n",
       "      <td>Every Time a Bell Rings</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15943414.0</td>\n",
       "      <td>10158.0</td>\n",
       "      <td>19744.0</td>\n",
       "      <td>2021-12-10 08:03:02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>9372</td>\n",
       "      <td>Single All The Way</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14315756.0</td>\n",
       "      <td>10161.0</td>\n",
       "      <td>19753.0</td>\n",
       "      <td>2021-12-15 10:10:36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9373 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                       Title    year  rating  dubious  \\\n",
       "0              0            Passage de Venus  1874.0     0.0      0.0   \n",
       "1              1           La Rosace Magique  1877.0     0.0      0.0   \n",
       "2              2  Sallie Gardner at a Gallop  1878.0     0.0      0.0   \n",
       "3              3           Le singe musicien  1878.0     0.0      0.0   \n",
       "4              4     Athlete Swinging a Pick  1881.0     0.0      0.0   \n",
       "...          ...                         ...     ...     ...      ...   \n",
       "9368        9368                   Love Hard  2021.0     2.0      0.0   \n",
       "9369        9369                     Cruella  2021.0     3.0      0.0   \n",
       "9370        9370             West Side Story  2021.0     3.0      0.0   \n",
       "9371        9371     Every Time a Bell Rings  2021.0     3.0      0.0   \n",
       "9372        9372          Single All The Way  2021.0     3.0      0.0   \n",
       "\n",
       "          imdbid       id  submitterid                 date  visible  \n",
       "0      3155794.0   9602.0      18880.0  2021-04-02 20:58:09      1.0  \n",
       "1     14495706.0   9804.0      19145.0  2021-05-11 00:11:22      1.0  \n",
       "2      2221420.0   9603.0      18882.0  2021-04-03 02:25:27      1.0  \n",
       "3     12592084.0   9806.0      19151.0  2021-05-11 23:38:54      1.0  \n",
       "4      7816420.0   9816.0      19162.0  2021-05-13 01:32:14      1.0  \n",
       "...          ...      ...          ...                  ...      ...  \n",
       "9368  10752004.0  10152.0      19735.0  2021-12-05 19:22:20      1.0  \n",
       "9369   3228774.0   9861.0      19231.0  2021-06-01 03:16:58      1.0  \n",
       "9370   3581652.0  10157.0      19743.0  2021-12-10 03:10:09      1.0  \n",
       "9371  15943414.0  10158.0      19744.0  2021-12-10 08:03:02      1.0  \n",
       "9372  14315756.0  10161.0      19753.0  2021-12-15 10:10:36      1.0  \n",
       "\n",
       "[9373 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "cwd = os.getcwd()\n",
    "path =\"/\".join(list(cwd.split('/')[0:-1])) \n",
    "\n",
    "top_movies = path+'/Data/webscrape/finalmovies.csv'\n",
    "movies_df = pd.read_csv(top_movies,header=0)\n",
    "bechdel_data=path+'/Data/bechdel/Bechdel_detailed.csv'\n",
    "bechdel_df= pd.read_csv(bechdel_data)\n",
    "bechdel_df.rename(columns={\"title\":\"Title\"}, inplace=True)\n",
    "bechdel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains information and metadata regarding the bechdel evaluation for a series of movies.\n",
    "The information most relevant to us the <b>rating column</b> that contains a number from 0 to 3, where:\n",
    "<ul>\n",
    "<li>0 means there are no two female characters, </li>\n",
    "<li>1 means if they exist, there is no talking between them, </li>\n",
    "<li>2 means if they talk, it is only  about a man,</li>\n",
    "<li>3 means it passes the test;</li>\n",
    "\n",
    "</ul>\n",
    "the column dubious states the submitter considered the rating dubious.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform cleaning and merging operations in order to get our final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOVIE_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Decade</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Samson and Delilah</td>\n",
       "      <td>40s</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Cecil B.DeMille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>The Bells of St. Mary</td>\n",
       "      <td>40s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Leo McCarey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Sergeant York</td>\n",
       "      <td>40s</td>\n",
       "      <td>War</td>\n",
       "      <td>Leo McCarey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Going My Way</td>\n",
       "      <td>40s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Howard Hawks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Forever Amber</td>\n",
       "      <td>40s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>John M. Stahl, Otto Preminger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Yankee Doodle Dandy</td>\n",
       "      <td>40s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Michael Curtiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>The Sea Chase</td>\n",
       "      <td>50s</td>\n",
       "      <td>War</td>\n",
       "      <td>John Farrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>The Bible</td>\n",
       "      <td>60s</td>\n",
       "      <td>Historical</td>\n",
       "      <td>John Huston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>Fiddler on the Roof</td>\n",
       "      <td>70s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Norman Jewison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77</td>\n",
       "      <td>Rogue One: A Star Wars Story</td>\n",
       "      <td>2010s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>Gareth Edwards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MOVIE_ID                         Title Decade       Genre  \\\n",
       "0         1            Samson and Delilah    40s  Historical   \n",
       "1         3         The Bells of St. Mary    40s     Musical   \n",
       "2         4                 Sergeant York    40s         War   \n",
       "3         5                  Going My Way    40s     Musical   \n",
       "4         6                 Forever Amber    40s       Drama   \n",
       "5         7           Yankee Doodle Dandy    40s     Musical   \n",
       "6        18                 The Sea Chase    50s         War   \n",
       "7        29                     The Bible    60s  Historical   \n",
       "8        39           Fiddler on the Roof    70s     Musical   \n",
       "9        77  Rogue One: A Star Wars Story  2010s      SCI-FI   \n",
       "\n",
       "                        Director  \n",
       "0                Cecil B.DeMille  \n",
       "1                    Leo McCarey  \n",
       "2                    Leo McCarey  \n",
       "3                   Howard Hawks  \n",
       "4  John M. Stahl, Otto Preminger  \n",
       "5                 Michael Curtiz  \n",
       "6                    John Farrow  \n",
       "7                    John Huston  \n",
       "8                 Norman Jewison  \n",
       "9                 Gareth Edwards  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#rename manually\n",
    "bechdel_df.loc[bechdel_df['Title'].str.contains('Rogue One'), 'Title'] = bechdel_df['Title'].str.replace('Rogue One', 'Rogue One: A Star Wars Story')\n",
    "bechdel_df.loc[bechdel_df['Title'].str.contains('Last Jedi'), 'Title'] = bechdel_df['Title'].str.replace('Star Wars: The Last Jedi', 'Star Wars: Episode VIII - The Last Jedi')\n",
    "bechdel_df.loc[bechdel_df['Title'].str.fullmatch('Star Wars'), 'Title'] = bechdel_df['Title'].str.replace('Star Wars', 'Star Wars: Episode IV - A New Hope')\n",
    "\n",
    "#remove special characters etc\n",
    "def normalize_string(s):\n",
    "    s = s.replace('&#39;','')\t\n",
    "    s = s.replace(\"'\", '')  # apostrophes with empty string\n",
    "    s = re.sub(r'\\W+', '', s)  # Remove non-alphanumeric \n",
    "    s = s.lower()  # Convert to lowercase\n",
    "    s = s.replace(' ', '_') \n",
    "    s = s.replace('the', '')# Replace spaces with underscores\n",
    "    s = s.replace('judgment', 'judgement')\n",
    "    return s\n",
    "\n",
    "\n",
    "bechdel_df['name_normalized'] = bechdel_df['Title'].apply(normalize_string)\n",
    "movies_df['name_normalized'] = movies_df['Title'].apply(normalize_string)\n",
    "\n",
    "final_df = pd.merge(bechdel_df, movies_df, on='name_normalized', how='right')\n",
    "\n",
    "#study missing values\n",
    "\n",
    "null_values_x= final_df['Title_x'].isna()\n",
    "null_values_x.sum()\n",
    "final_df[null_values_x]\n",
    "\n",
    "bechdel_no_data= final_df[null_values_x]\n",
    "bechdel_no_data = bechdel_no_data.drop([\"Unnamed: 0\",\"name_normalized\"], axis=1)\n",
    "bechdel_no_data = bechdel_no_data.dropna(axis=1)\n",
    "bechdel_no_data.rename(columns={\"Title_y\":\"Title\"}, inplace= True)\n",
    "bechdel_no_data.reset_index(drop=True, inplace=True) #these are our movies that do not have any data regarding bechdel rules\n",
    "\n",
    "#view movies that do not contain information\n",
    "bechdel_no_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 of our selected movies, most of them released in the beginning of our time range, have not yet been evaluated.\n",
    "Let's look at the information regarding the rest of the movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Decade</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Director</th>\n",
       "      <th>year</th>\n",
       "      <th>bechdel_rating</th>\n",
       "      <th>dubious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Song of the South</td>\n",
       "      <td>40s</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Wilfred Jackson, Harve Foster</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samson and Delilah</td>\n",
       "      <td>40s</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Cecil B.DeMille</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>40s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Victor Fleming</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Bells of St. Mary</td>\n",
       "      <td>40s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Leo McCarey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sergeant York</td>\n",
       "      <td>40s</td>\n",
       "      <td>War</td>\n",
       "      <td>Leo McCarey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>2010s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Man of Steel</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Zack Snyder</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Rogue One: A Star Wars Story</td>\n",
       "      <td>2010s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>Gareth Edwards</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 2</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>David Yates</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>X-Men: Days of Future Past</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Bryan Singer</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Title Decade       Genre  \\\n",
       "0                              Song of the South    40s   Animation   \n",
       "1                             Samson and Delilah    40s  Historical   \n",
       "2                             Gone with the Wind    40s       Drama   \n",
       "3                          The Bells of St. Mary    40s     Musical   \n",
       "4                                  Sergeant York    40s         War   \n",
       "..                                           ...    ...         ...   \n",
       "76                                        Avatar  2010s      SCI-FI   \n",
       "77                                  Man of Steel  2010s      Action   \n",
       "78                  Rogue One: A Star Wars Story  2010s      SCI-FI   \n",
       "79  Harry Potter and the Deathly Hallows: Part 2  2010s     Fantasy   \n",
       "80                    X-Men: Days of Future Past  2010s      Action   \n",
       "\n",
       "                         Director    year  bechdel_rating  dubious  \n",
       "0   Wilfred Jackson, Harve Foster  1946.0             2.0      0.0  \n",
       "1                 Cecil B.DeMille     NaN             NaN      NaN  \n",
       "2                  Victor Fleming  1939.0             3.0      NaN  \n",
       "3                     Leo McCarey     NaN             NaN      NaN  \n",
       "4                     Leo McCarey     NaN             NaN      NaN  \n",
       "..                            ...     ...             ...      ...  \n",
       "76                  James Cameron  2009.0             3.0      0.0  \n",
       "77                    Zack Snyder  2013.0             3.0      0.0  \n",
       "78                 Gareth Edwards     NaN             NaN      NaN  \n",
       "79                    David Yates  2011.0             3.0      1.0  \n",
       "80                   Bryan Singer  2014.0             1.0      0.0  \n",
       "\n",
       "[81 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_bechdel = final_df.drop(['Unnamed: 0','submitterid','date','name_normalized', 'id','visible','Title_x'],axis=1)\n",
    "movies_bechdel.rename(columns={\"Title_y\":\"Title\",\"rating\":\"bechdel_rating\"}, inplace= True)\n",
    "movies_bechdel = movies_bechdel[['Title', 'Decade', 'Genre', 'Director', 'year', 'bechdel_rating', 'dubious']]\n",
    "\n",
    "title_duplicates = movies_bechdel[movies_bechdel['Title'].duplicated(keep=False)]\n",
    "#drop duplicates by their index\n",
    "movies_bechdel= movies_bechdel.drop([24,25,29,77])\n",
    "movies_bechdel.reset_index(drop=True, inplace=True)\n",
    "\n",
    "movies_bechdel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more specific information we can query the dataframe directly, for example if we want to take a look at which of our selected films have passed the bechdel test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Decade</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Director</th>\n",
       "      <th>year</th>\n",
       "      <th>bechdel_rating</th>\n",
       "      <th>dubious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>40s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Victor Fleming</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Snake Pit</td>\n",
       "      <td>40s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Anatole Litvak</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Here To Eternity</td>\n",
       "      <td>50s</td>\n",
       "      <td>War</td>\n",
       "      <td>Fred Zinneman</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White Christmas</td>\n",
       "      <td>50s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Michael Kurtiz</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quo Vadis?</td>\n",
       "      <td>50s</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Mervyn LeRoy, Anthony Mann</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cat on a Hot Tin Roof</td>\n",
       "      <td>50s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Richard Brooks</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Some like it hot</td>\n",
       "      <td>50s</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Billy Wilder</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>All About Eve</td>\n",
       "      <td>50s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Joseph L. Mankiewicz</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Sound of Music</td>\n",
       "      <td>60s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Robert Wise</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mary Poppins</td>\n",
       "      <td>60s</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>Robert Stevenson</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>60s</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Joseph L. Mankiewicz</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>West Side Story</td>\n",
       "      <td>60s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Jerome Robbins, Robert Wise</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>60s</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>Alfred Hitchcock</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>JAWS</td>\n",
       "      <td>70s</td>\n",
       "      <td>Horror</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Exorcist</td>\n",
       "      <td>70s</td>\n",
       "      <td>Horror</td>\n",
       "      <td>William Friedkin</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grease</td>\n",
       "      <td>70s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Randal Kleiser</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E.T. the Extra-Terrestrial</td>\n",
       "      <td>80s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ghostbusters</td>\n",
       "      <td>80s</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>Ivan Reitman</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Superman II</td>\n",
       "      <td>80s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Richard Lester</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>90s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace</td>\n",
       "      <td>90s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>George Lucas</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Jurassic Park</td>\n",
       "      <td>90s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Independence Day</td>\n",
       "      <td>90s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>Roland Emmerich</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ghost</td>\n",
       "      <td>90s</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Jerry Zucker</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>90s</td>\n",
       "      <td>Action</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Harry Potter and the Half Blood Prince</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>David Yates</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Transformers</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Michael Bay</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Harry Potter and the Sorcerers Stone</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>Chris Columbus</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Anthony Russo, Joe Russo</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Black Panther</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Ryan Coogler</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Star Wars: The Force Awakens</td>\n",
       "      <td>2010s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>George Lucas</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Star Wars: Episode VIII - The Last Jedi</td>\n",
       "      <td>2010s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>George Lucas</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>2010s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Man of Steel</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Zack Snyder</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 2</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>David Yates</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title Decade       Genre  \\\n",
       "0                                  Gone with the Wind    40s       Drama   \n",
       "1                                       The Snake Pit    40s       Drama   \n",
       "2                               From Here To Eternity    50s         War   \n",
       "3                                     White Christmas    50s     Musical   \n",
       "4                                          Quo Vadis?    50s  Historical   \n",
       "5                               Cat on a Hot Tin Roof    50s       Drama   \n",
       "6                                    Some like it hot    50s      Comedy   \n",
       "7                                       All About Eve    50s       Drama   \n",
       "8                                  The Sound of Music    60s     Musical   \n",
       "9                                        Mary Poppins    60s     Fantasy   \n",
       "10                                          Cleopatra    60s  Historical   \n",
       "11                                    West Side Story    60s     Musical   \n",
       "12                                             Psycho    60s    Thriller   \n",
       "13                                               JAWS    70s      Horror   \n",
       "14                                       The Exorcist    70s      Horror   \n",
       "15                                             Grease    70s     Musical   \n",
       "16                         E.T. the Extra-Terrestrial    80s      SCI-FI   \n",
       "17                                       Ghostbusters    80s     Fantasy   \n",
       "18                                        Superman II    80s      Action   \n",
       "19                                            Titanic    90s       Drama   \n",
       "20          Star Wars: Episode I - The Phantom Menace    90s      SCI-FI   \n",
       "21                                      Jurassic Park    90s      SCI-FI   \n",
       "22                                   Independence Day    90s      SCI-FI   \n",
       "23                                              Ghost    90s     Romance   \n",
       "24                         Terminator 2: Judgment Day    90s      Action   \n",
       "25                                    The Dark Knight  2000s      Action   \n",
       "26            Harry Potter and the Half Blood Prince   2000s     Fantasy   \n",
       "27                                       Transformers  2000s      Action   \n",
       "28  Pirates of the Caribbean: The Curse of the Bla...  2000s      Action   \n",
       "29               Harry Potter and the Sorcerers Stone  2000s     Fantasy   \n",
       "30                                  Avengers: Endgame  2010s      Action   \n",
       "31                                      Black Panther  2010s      Action   \n",
       "32                       Star Wars: The Force Awakens  2010s      SCI-FI   \n",
       "33            Star Wars: Episode VIII - The Last Jedi  2010s      SCI-FI   \n",
       "34                                             Avatar  2010s      SCI-FI   \n",
       "35                                       Man of Steel  2010s      Action   \n",
       "36       Harry Potter and the Deathly Hallows: Part 2  2010s     Fantasy   \n",
       "\n",
       "                       Director    year  bechdel_rating  dubious  \n",
       "0                Victor Fleming  1939.0             3.0      NaN  \n",
       "1                Anatole Litvak  1948.0             3.0      0.0  \n",
       "2                 Fred Zinneman  1953.0             3.0      0.0  \n",
       "3                Michael Kurtiz  1954.0             3.0      0.0  \n",
       "4    Mervyn LeRoy, Anthony Mann  1951.0             3.0      1.0  \n",
       "5                Richard Brooks  1958.0             3.0      0.0  \n",
       "6                  Billy Wilder  1959.0             3.0      0.0  \n",
       "7          Joseph L. Mankiewicz  1950.0             3.0      NaN  \n",
       "8                   Robert Wise  1965.0             3.0      0.0  \n",
       "9              Robert Stevenson  1964.0             3.0      0.0  \n",
       "10         Joseph L. Mankiewicz  1963.0             3.0      0.0  \n",
       "11  Jerome Robbins, Robert Wise  1961.0             3.0      0.0  \n",
       "12             Alfred Hitchcock  1960.0             3.0      0.0  \n",
       "13             Steven Spielberg  1975.0             3.0      0.0  \n",
       "14             William Friedkin  1973.0             3.0      0.0  \n",
       "15               Randal Kleiser  1978.0             3.0      0.0  \n",
       "16             Steven Spielberg  1982.0             3.0      1.0  \n",
       "17                 Ivan Reitman  2016.0             3.0      0.0  \n",
       "18               Richard Lester  1980.0             3.0      1.0  \n",
       "19                James Cameron  1997.0             3.0      NaN  \n",
       "20                 George Lucas  1999.0             3.0      0.0  \n",
       "21             Steven Spielberg  1993.0             3.0      NaN  \n",
       "22              Roland Emmerich  1996.0             3.0      0.0  \n",
       "23                 Jerry Zucker  1990.0             3.0      0.0  \n",
       "24                James Cameron  1991.0             3.0      1.0  \n",
       "25            Christopher Nolan  2008.0             3.0      1.0  \n",
       "26                  David Yates  2009.0             3.0      NaN  \n",
       "27                  Michael Bay  2007.0             3.0      0.0  \n",
       "28               Gore Verbinski  2003.0             3.0      0.0  \n",
       "29               Chris Columbus  2001.0             3.0      0.0  \n",
       "30     Anthony Russo, Joe Russo  2019.0             3.0      0.0  \n",
       "31                 Ryan Coogler  2018.0             3.0      0.0  \n",
       "32                 George Lucas  2015.0             3.0      0.0  \n",
       "33                 George Lucas  2017.0             3.0      0.0  \n",
       "34                James Cameron  2009.0             3.0      0.0  \n",
       "35                  Zack Snyder  2013.0             3.0      0.0  \n",
       "36                  David Yates  2011.0             3.0      1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bechdel_passed = movies_bechdel[movies_bechdel[\"bechdel_rating\"] == 3.0] \n",
    "bechdel_passed.reset_index(drop=True, inplace=True)\n",
    "bechdel_passed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "### Character Description\n",
    "In this step we will be diving into the **actual descriptions of characters in the scripts**. The idea of using descriptions of the characters is to get an understanding of how the camera wants to show certain features of the characters through the use of angles: in this way the camera becomes the gaze and the (non-male) character becomes the object for the gaze.\n",
    "\n",
    "Our aim is to extract automatically such descriptions from the scripts using Natural Language Processing and show the words which are often used in the describing characters (both male and non-male), revealing the differences in the way they are portayed. We also aim to **categorize female descriptions** in terms of *body descriptions* relating to the male gaze, and *dubious but problematic* descriptions relating to both the body and the personality of female characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/macuser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/macuser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pandas import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# reading the script files\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "#nltk tools\n",
    "import nltk \n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "part = wn.synsets('body_part')[0]\n",
    "\n",
    "def is_body_part(candidate):\n",
    "    for ss in wn.synsets(candidate):\n",
    "        # only get those where the synset matches exactly\n",
    "        name = ss.name().split(\".\", 1)[0]\n",
    "        if name != candidate:\n",
    "            continue\n",
    "        hit = part.lowest_common_hypernyms(ss)\n",
    "        if hit and hit[0] == part:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "path =\"/\".join(list(cwd.split('/')[0:-1])) \n",
    " \n",
    "# assign directory\n",
    "directory = path+'/Data/scripts'\n",
    " \n",
    "# iterate over script files\n",
    "ignore='.DS_Store'\n",
    "files = []\n",
    "for filename in os.scandir(directory):\n",
    "\n",
    "     if filename.is_file() and ignore not in str(filename):\n",
    "        files.append(filename.path)\n",
    " \n",
    "def get_title(file_name): #get/clean script titles\n",
    "    title = file_name.split(\"/\")[-1]\n",
    "    \n",
    "    return title\n",
    "\n",
    "#keywords to look out for (body descriptions and adjectives). The last two lists contain problematic vocabulary often associated with females.\n",
    "\n",
    "words_0= ['body', 'blonde', 'brunette', 'lips', 'beauty', 'age', 'smile', 'pants', 'skirt', 'dress', 'shirt', 'glow', 'shorts', 'hand','face','finger', 'throat','neck','hair','skin','arm','figure','shoulder'] \n",
    "adj_0=['beautiful', 'gorgeous', 'cute', 'pretty', 'devoted','divine', 'lawful','housewife', 'silly', 'frightening']\n",
    "words_1=['ass', 'buxom','chest','boob', 'boob', 'bosom','buttock','breast', 'breasts','thigh', 'bottom', 'curve', 'underwear','thong','figure' 'panty', 'stocking', 'panties', 'lingerie', 'bra', 'nipple','vagina','cunt','womanhood']\n",
    "adj_1= ['seductive','sexy','trashy', 'nude', 'sexuality','promiscuous', 'sexual', 'ignorant', 'hot', 'hottie', 'erotic','fuck-me', 'fuck me','juicy','sultry', 'banging','naked', 'topless',\n",
    "        'stupid','helpless','fragile','dumb','weak','pitiful','enchanting', 'stunning','toned', 'breathtaking', 'breath-taking', 'perfect', 'bitch','slut','crazy',\n",
    "        'sassy','dramatic','bubbly','hysterical', 'bitchy','catty','tease','prude','trollop']\n",
    "\n",
    "\n",
    "#dictionary to store the data for each movie, for lists words_0 and adj_0\n",
    "movies_dict={}\n",
    "#dictionary  to store the data for each movie, for lists words_1 and adj_1\n",
    "movies_dict_1={}\n",
    "\n",
    "\n",
    "\n",
    "for f in files:\n",
    "    movie_title = get_title(f)\n",
    "    reader = PdfReader(f)\n",
    "    lst=[]\n",
    "    for i in range(0,len(reader.pages)):\n",
    "        page = reader.pages[i]\n",
    "        text = page.extract_text()\n",
    "        lst.append(text)\n",
    "\n",
    "    #dictionaries to store words and their number of occurences, for each list (body depiction and dubious words)\n",
    "    word_counts={}\n",
    "    word_counts_1={}\n",
    "    \n",
    "    check = [\"she\", \"her\", \"woman\", \"woman's\", \"women\", \"women's\", \"she's\",\"girl\",\"girl's\",\"girls\"]\n",
    "\n",
    "    for i in lst:\n",
    "        tokens = word_tokenize(i)\n",
    "\n",
    "        for k in range(0,len(tokens)):\n",
    "            #lemmatize\n",
    "            tokens[k] = lemmatizer.lemmatize(tokens[k])\n",
    "\n",
    "            #if the token is a body part or in the list of keywords\n",
    "            if is_body_part(tokens[k].lower()) == True or tokens[k].lower() in words_0+adj_0:  \n",
    "                \n",
    "                #get the n-grams near the token\n",
    "                gram2 = tokens[k-2].lower()\n",
    "                gram1 = tokens[k-1].lower()\n",
    "                gram = tokens[k].lower()\n",
    "                if k+1 in range(-len(tokens), len(tokens)):\n",
    "                  gram0 = tokens[k+1].lower()\n",
    "\n",
    "                #check whether they are associated with female pronouns\n",
    "                if  gram2 in check or gram1 in check or gram0 in check:\n",
    "\n",
    "                  #populate the dictionary\n",
    "                  if tokens[k].lower() in word_counts:\n",
    "                      word_counts[tokens[k].lower()] += 1\n",
    "                  else:\n",
    "                      word_counts[tokens[k].lower()] = 1\n",
    "\n",
    "            #if the token is in the list of our problematic keywords\n",
    "            if tokens[k].lower() in words_1+adj_1:\n",
    "\n",
    "                #check the n-grams around the problematic token\n",
    "                gram2 = tokens[k-2].lower()\n",
    "                gram1 = tokens[k-1].lower()\n",
    "                gram = tokens[k].lower()\n",
    "                if k+1 in range(-len(tokens), len(tokens)):\n",
    "                  gram0 = tokens[k+1].lower()\n",
    "\n",
    "                #check whether they are associated with female pronouns\n",
    "                if gram2 in check or gram1 in check or gram in check or gram0 in check:\n",
    "            \n",
    "                    #populate the dictionary for problematic keyword occurences\n",
    "                    if tokens[k].lower() in word_counts_1:\n",
    "                        word_counts_1[tokens[k].lower()] += 1\n",
    "                    else:\n",
    "                        word_counts_1[tokens[k].lower()] = 1\n",
    "    \n",
    "    #assign findings to the general dictionary for each key that is our movie\n",
    "    movies_dict[movie_title] = word_counts\n",
    "    movies_dict_1[movie_title] = word_counts_1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The above code iterates over the scripts in our folder, and looks for:\n",
    "<ul>\n",
    "    <li>words that are used to describe one's body, with the function \"is_body_part\", </li>\n",
    "    <li> words that we have deemed inappropriate for describing a female's body and character, given in a list of strings.</li>\n",
    "    \n",
    "</ul>\n",
    "</p>\n",
    "<p>Then, if these words are associated with <b>female characters</b> -through specific words and pronouns- they are added in their corresponding dictionaries, where each key is the movie name, whose key is a dictionary containing the words and the number of their occurence.</p>\n",
    "\n",
    "Let's take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptions: ('psycho.pdf', {'face': 17, 'leg': 1, 'foot': 1, 'arm': 5, 'temple': 1, 'head': 7, 'dress': 2, 'small': 1, 'horn': 1, 'eye': 17, 'hand': 8, 'left': 7, 'feature': 1, 'smile': 4, 'back': 2, 'throat': 1, 'right': 4, 'hair': 2, 'figure': 1, 'index': 1, 'finger': 2}) \n",
      " problematic descriptions: ('psycho.pdf', {'bra': 3})\n"
     ]
    }
   ],
   "source": [
    "print('descriptions:',list(movies_dict.items())[0],'\\n','problematic descriptions:',list(movies_dict_1.items())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next, we want to create a dataframe with our all occurences for each film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>script_name</th>\n",
       "      <th>count</th>\n",
       "      <th>inappropriate_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>psycho.pdf</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spiderman</td>\n",
       "      <td>spiderman.pdf</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Man of Steel</td>\n",
       "      <td>ManofSteelnSecondDraftn.pdf</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001: A Space Odyssey</td>\n",
       "      <td>2001-space-odyssey.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beverly Hills Cop II</td>\n",
       "      <td>beverly-hills-copII.pdf</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>terminator-2-judgement-day-1991.pdf</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace</td>\n",
       "      <td>starwars_thephantomenace.php</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "      <td>pirates-of-the-caribbean-the-curse-of-the-blac...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>forrestgump.php</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>The Bible</td>\n",
       "      <td>The Bible.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                movie  \\\n",
       "0                                              Psycho   \n",
       "1                                           Spiderman   \n",
       "2                                        Man of Steel   \n",
       "3                               2001: A Space Odyssey   \n",
       "4                                Beverly Hills Cop II   \n",
       "..                                                ...   \n",
       "75                         Terminator 2: Judgment Day   \n",
       "76          Star Wars: Episode I - The Phantom Menace   \n",
       "77  Pirates of the Caribbean: The Curse of the Bla...   \n",
       "78                                       Forrest Gump   \n",
       "79                                          The Bible   \n",
       "\n",
       "                                          script_name  count  \\\n",
       "0                                          psycho.pdf     86   \n",
       "1                                       spiderman.pdf     57   \n",
       "2                         ManofSteelnSecondDraftn.pdf     70   \n",
       "3                              2001-space-odyssey.pdf      2   \n",
       "4                             beverly-hills-copII.pdf     11   \n",
       "..                                                ...    ...   \n",
       "75                terminator-2-judgement-day-1991.pdf    132   \n",
       "76                       starwars_thephantomenace.php      8   \n",
       "77  pirates-of-the-caribbean-the-curse-of-the-blac...     60   \n",
       "78                                    forrestgump.php     20   \n",
       "79                                      The Bible.pdf      3   \n",
       "\n",
       "    inappropriate_count  \n",
       "0                     3  \n",
       "1                     2  \n",
       "2                     1  \n",
       "3                     0  \n",
       "4                     2  \n",
       "..                  ...  \n",
       "75                    0  \n",
       "76                    0  \n",
       "77                    0  \n",
       "78                    6  \n",
       "79                    0  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get total amount for each movie\n",
    "movie_stats = {movie: sum(words.values()) for movie, words in movies_dict.items()}\n",
    "movie_stats_inapp = {movie: sum(words.values()) for movie, words in movies_dict_1.items()}\n",
    "\n",
    "movie_descriptions = DataFrame.from_dict(movie_stats, orient='index', columns=['count'])\n",
    "movie_descriptions_inapp= DataFrame.from_dict(movie_stats_inapp, orient='index', columns=['inappropriate_count'])\n",
    "\n",
    "movie_descriptions.reset_index(inplace=True)\n",
    "movie_descriptions_inapp.reset_index(inplace=True)\n",
    "\n",
    "movie_descriptions = movie_descriptions.rename(columns={'index':'script_name'})\n",
    "movie_descriptions_inapp = movie_descriptions_inapp.rename(columns={'index':'script_name'})\n",
    "\n",
    "movie_desc_graph= merge(movie_descriptions,movie_descriptions_inapp, left_on='script_name', right_on='script_name')\n",
    "\n",
    "\n",
    "# difflib  will allow us to match our script names to the appropriate movie titles\n",
    "\n",
    "import difflib\n",
    "df_all_movies = read_csv(path+'/Data/Dialogue/dialogue_bechdel.csv')\n",
    "import difflib\n",
    "titles = df_all_movies['Title'].to_list()\n",
    "titles_to_check= movie_desc_graph['script_name'].to_list()\n",
    "titles_match=[]\n",
    "for i in titles_to_check:\n",
    "    titles_match.append(difflib.get_close_matches(i, titles, len(titles), 0)[0])\n",
    "\n",
    "fem_desc_graph = DataFrame(list(zip(titles_match,titles_to_check)),\n",
    "               columns =['movie', 'script_name'])\n",
    "fem_desc_graph  = fem_desc_graph.merge(movie_desc_graph, left_on=\"script_name\", right_on= \"script_name\")\n",
    "fem_desc_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Character Dialogue\n",
    "In this step we are extracting all the dialogues spoken by male and non-male characters for each script automatically also using NLP tasks. The aim here is to show just how much the **division and representation of words** are given to men vs non-men characters. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing required modules\n",
    "from PyPDF2 import PdfReader\n",
    "import nltk \n",
    "from nltk.corpus import wordnet as wn\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import gender_guesser.detector as gender\n",
    "import csv\n",
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    " \n",
    "# nltk.download('wordnet')\n",
    "\n",
    "part = wn.synsets('body_part')[0]\n",
    "\n",
    "\n",
    "# assign directory\n",
    "directory = '../Data/scripts/'\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "\n",
    "files = []\n",
    "for filename in os.scandir(directory):\n",
    "    if filename.is_file():\n",
    "        files.append(filename.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This function is used to check if there is any word which is wither an upper case or as length 1 or 0 or if it has : in it\n",
    "def checkUpper(s):\n",
    "    if len(s)>1 and s.isupper()!=True:\n",
    "        if \":\" in e:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    elif len(s)==1 or len(s)==0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "# This function simply checks if there are any numbers in the string\n",
    "def has_numbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "# files = ['../Data/scripts/ET_1.pdf']\n",
    "# Data/scripts/avatar.php','Data/scripts/batmanforever.php'\n",
    "# 'Data/scripts/backtothefuture.pdf\n",
    "# dic={}\n",
    "\n",
    "# This is the main dictionary where everything will be eventually stored\n",
    "\n",
    "Maindic={}\n",
    "for f in files:\n",
    "    dic={}\n",
    "\n",
    "    title = f.split(\"/\")[-1]\n",
    "    print('\\n','---------------------------------',title,'----------------------------------','\\n')\n",
    "    reader = PdfReader(f)\n",
    "\n",
    "    lst=[]\n",
    "   \n",
    "    # for each page that the reader has read from the pdf\n",
    "    for i in range(0,len(reader.pages)):\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        page = reader.pages[i]\n",
    "        text = page.extract_text()\n",
    "#         splitting the text of the page on the basis of new line\n",
    "        ls= text.split('\\n')\n",
    "        \n",
    "        \n",
    "      \n",
    "      \n",
    "        for j in range(0,len(ls)):\n",
    "\n",
    "#             for each line we clean it\n",
    "            cleaned = ls[j].strip()\n",
    "            \n",
    "# Then we check if it is one word or two words or if it has : in it .\n",
    "# this is to basically extract that this will be a character who will be saying some dialgoue\n",
    "            if (len(cleaned.split(\" \"))==1 or len(cleaned.split(\" \"))==2) and (cleaned.isupper() or \":\" in cleaned) and '!' not in cleaned and has_numbers(cleaned)==False:\n",
    "                \n",
    "            \n",
    "#             Then we check of the word index that we are iterating over has 6 lines or not. We do this check for 5,4,3 lines too\n",
    "\n",
    "                if j+6 in range(-len(ls), len(ls)):\n",
    "#                     Here we are adding all the lines together in one dialogue\n",
    "                    word = ls[j+1].strip()+' '+ls[j+2].strip()+' '+ls[j+3].strip()+' '+ls[j+4].strip()+ ' '+ls[j+5].strip()+ ' '+ls[j+6].strip() \n",
    "                    \n",
    "                    newword=[]\n",
    "#             Here we are checking all the lines that we added. we want to see if all the lines are actually dialogoues and not \n",
    "# continuation of some other character dialogue so we use the checkUpper function and break it whereever theres a doubt\n",
    "            \n",
    "\n",
    "                    for e in word.split(' '):\n",
    "                        \n",
    "                        if checkUpper(e):\n",
    "                            newword.append(e)\n",
    "                        else:\n",
    "                            break\n",
    "#                     print(newword)\n",
    "\n",
    "                    word = ' '.join(newword)\n",
    "                    \n",
    "#                     Then we assign the character name to a local dictionary and all the dialogues will become the values\n",
    "                    if ls[j] not in dic:\n",
    "                        \n",
    "                        dic[ls[j].strip()]= word\n",
    "                        \n",
    "                    else:\n",
    "                        dic[ls[j].strip()]=dic[ls[j]] + ' '+word\n",
    "                        \n",
    "                    \n",
    "                elif j+5 in range(-len(ls), len(ls)):\n",
    "                    \n",
    "                    word = ls[j+1].strip()+' '+ls[j+2].strip()+' '+ls[j+3].strip()+' '+ls[j+4].strip()+ ' '+ls[j+5].strip()\n",
    "                    newword=[]\n",
    "\n",
    "                    for e in word.split(' '):\n",
    "                        \n",
    "                        if checkUpper(e):\n",
    "                            newword.append(e)\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    word = ' '.join(newword)\n",
    "                    \n",
    "                    if ls[j] not in dic:\n",
    "                        \n",
    "                        dic[ls[j].strip()]= word\n",
    "                        \n",
    "                    else:\n",
    "                        dic[ls[j].strip()]=dic[ls[j]] + ' '+word         \n",
    "                        \n",
    "\n",
    "                elif j+4 in range(-len(ls), len(ls)):\n",
    "                    word = ls[j+1].strip()+' '+ls[j+2].strip()+' '+ls[j+3].strip()+' '+ls[j+4].strip()\n",
    "                    newword=[]\n",
    "\n",
    "                    for e in word.split(' '):\n",
    "                        \n",
    "                        if checkUpper(e):\n",
    "                            newword.append(e)\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    word = ' '.join(newword)\n",
    "                    \n",
    "                    if ls[j] not in dic:\n",
    "                        \n",
    "                        dic[ls[j].strip()]= word\n",
    "                        \n",
    "                    else:\n",
    "                        dic[ls[j].strip()]=dic[ls[j]] + ' '+word\n",
    "                        \n",
    "                        \n",
    "#                 Doing for 3 lines because the above code already caters to the lines that already exist \n",
    "\n",
    "                elif j+3 in range(-len(ls), len(ls)):\n",
    "                    word = ls[j+1].strip()+' '+ls[j+2].strip()+' '+ls[j+3].strip()\n",
    "                    newword=[]\n",
    "\n",
    "                    for e in word.split(' '):\n",
    "                        \n",
    "                        if checkUpper(e):\n",
    "                            newword.append(e)\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    word = ' '.join(newword)\n",
    "                    \n",
    "                    if ls[j] not in dic:\n",
    "                        \n",
    "                        dic[ls[j].strip()]= word\n",
    "                        \n",
    "                    else:\n",
    "                        dic[ls[j].strip()]=dic[ls[j]] + ' '+word\n",
    "                        \n",
    "          \n",
    "   \n",
    "        Maindic[title] = dic\n",
    "#     Here is where we save each of the dic for each script in a main dic\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#   saving in a txt file\n",
    "with open('convert.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(Maindic))\n",
    "    \n",
    "\n",
    "# reading the data from the file\n",
    "with open('convert.txt') as f:\n",
    "    data = f.read()\n",
    "  \n",
    "\n",
    "      \n",
    "# # reconstructing the data as a dictionary\n",
    "js = json.loads(data)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = gender.Detector(case_sensitive=False)\n",
    "data=[]\n",
    "\n",
    "# Here we are first cleaning some of the names that we have. We might have some apostraphe or capital small or decimals at \n",
    "# beginning or end of the word which we want to clean. Then we will be using a python library called gender guesser which\n",
    "# takes a name and then assignes the gender. it is either male, female, mostly male, mostly female, androgynous.\n",
    "\n",
    "\n",
    "for key,value in js.items():\n",
    "#     if key == 'titanic-numbered.pdf':\n",
    "    print(\"-----------------\"+key+\"-----------------------\")\n",
    "#     data.append([key,'','',''])\n",
    "    #     Sorted = sorted(value, key=lambda k: len(d[k]), reverse=True)\n",
    "    for k in sorted(value, key=lambda k: len(value[k]), reverse=True):\n",
    "        if len(value[k])>=10 and len(k)>=2:\n",
    "            name = k.split(\" \")[0]\n",
    "            name  = re.sub(r'\\'\\w+', '', name)\n",
    "            name  = re.sub(r'\\-\\w+', '', name)\n",
    "            name  = re.sub(r'\\:','', name)\n",
    "            name  = re.sub(r'\\.','', name)\n",
    "            name  = re.sub(r'(CONT)','', name)\n",
    "            name  = re.sub(r'','', name)\n",
    "            name = name.strip(\"()\")\n",
    "            name = name.strip('\"')\n",
    "            print([key,k,name,\"m\",len(value[k])])\n",
    "            \n",
    "            if d.get_gender(name) == \"male\":\n",
    "                data.append([key,k,name,\"m\",len(value[k])])\n",
    "            elif d.get_gender(name) == \"female\":\n",
    "                data.append([key,k,name,\"f\",len(value[k])])\n",
    "            elif d.get_gender(name) == \"mostly_male\":\n",
    "                data.append([key,k,name,\"m\",len(value[k])])\n",
    "            elif d.get_gender(name) == \"mostly_female\":\n",
    "                data.append([key,k,name,\"f\",len(value[k])])\n",
    "            elif d.get_gender(name) == \"andy\":\n",
    "                data.append([key,k,name,\"m\",len(value[k])])\n",
    "            else:\n",
    "                data.append([key,k,name,\"u\",len(value[k])])\n",
    "            \n",
    "            \n",
    "#             print (k,len(value[k]),d.get_gender(k.split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "header = ['movie','name from script', 'lemmatized name','gender', 'len of words']\n",
    "\n",
    "# Here we save all the results in an excel file and manually fix for the names that could not be populated.\n",
    "\n",
    "with open('char.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # write multiple rows\n",
    "    writer.writerows(data)\n",
    "\n",
    "# read by default 1st sheet of an excel file\n",
    "df = pd.read_excel('char.xlsx')\n",
    "\n",
    "# After reading from the excel we group by on the basis of the movie to get the sum of male and female characters.\n",
    "df2 = df.groupby(['movie','gender'])['len of words'].sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# movies={}\n",
    "\n",
    "    \n",
    "#     dic={}\n",
    "#     if row['movie'] not in movies:\n",
    "#         movies[row['movie']]\n",
    "#     else:\n",
    "#         print(row['movie'], row['name from script'],row[\"lemmatized name\"],row[\"gender\"],row[\"len of words\"])\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddic={}\n",
    "for index, row in df2.iterrows():\n",
    "#     lst=[]\n",
    "    if row['movie'] not in ddic:\n",
    "        if row['gender'] == \"m\":\n",
    "            ddic[row[\"movie\"]]=[('m',row['len of words'])]\n",
    "        elif row['gender'] == \"f\":\n",
    "            ddic[row[\"movie\"]]=[('f',row['len of words'])]\n",
    "    else:\n",
    "        if row['gender'] == \"m\":\n",
    "#             print(m,ddic[row['movie']])\n",
    "            ddic[row[\"movie\"]].append(('m',row['len of words']))\n",
    "        elif row['gender'] == \"f\":\n",
    "#             print(m,ddic[row['movie']])\n",
    "            ddic[row[\"movie\"]].append(('f',row['len of words']))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ddic)\n",
    "lss1 =[]\n",
    "lss2 = []\n",
    "lss3 = []\n",
    "lss4 = []\n",
    "\n",
    "# Here we are able to make a dataframe of male and female dialogue divisions for each movie\n",
    "for key in ddic:\n",
    "    if len(ddic[key])>1:\n",
    "        print(key,ddic[key])\n",
    "        lss1.append(key)\n",
    "        if ddic[key][0][0]=='m':\n",
    "            lss2.append(ddic[key][0][1])\n",
    "        if ddic[key][0][0]=='f':\n",
    "            lss3.append(ddic[key][0][1])\n",
    "        if ddic[key][1][0]=='m':\n",
    "            lss2.append(ddic[key][1][1])\n",
    "        if ddic[key][1][0]=='f':\n",
    "            lss3.append(ddic[key][1][1])\n",
    "            \n",
    "            \n",
    "            \n",
    "df_f = pd.DataFrame(list(zip(lss1,lss2,lss3)),\n",
    "               columns =['Name', 'm','f'])\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f[\"total\"] = df_f[\"m\"] + df_f[\"f\"]\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the percentage of male dialogue from total\n",
    "df_f[\"male_percen\"] = df.loc[df['column_name'] == some_value](df_f[\"m\"] / df_f[\"total\"])*100\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.read_csv('../Data/bechdel/all_movies_bechdel.csv')\n",
    "# !pip install difflib\n",
    "\n",
    "# Here we are using a library difflib which will allow us to get the actual names of the movies from the dataset already prepared\n",
    "\n",
    "dd_1 = df_m['Title'].to_list()\n",
    "dd_2= df_f['Name'].to_list()\n",
    "dd_3 = df_f['male_percen'].to_list()\n",
    "dd_4=[]\n",
    "for i in dd_2:\n",
    "    dd_4.append(difflib.get_close_matches(i, dd_1, len(dd_1), 0)[0])\n",
    "#     print(i,difflib.get_close_matches(i, dd_1, len(dd_1), 0)[0])\n",
    "\n",
    "df_5 = pd.DataFrame(list(zip(dd_2,dd_4,dd_3)),\n",
    "               columns =['script_name', 'movie_name','male_percen'])\n",
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.to_csv('male_percen.csv')\n",
    "final = pd.read_csv('male_percen.csv')\n",
    "score=[]\n",
    "l = final['male_percen'].to_list()\n",
    "\n",
    "# Here we are assigning a score for the male percentages of dialogues. \n",
    "# If a male character has less than or equal to 50% of the overall dialougue in the script: 0%\n",
    "# If a male character has more than or equal to 70% of the overall dialougue in the script: 25%\n",
    "# If a male character has dialogue between 51% to 69% of the overall dialougue in the script then the percentage \n",
    "# will be assigned on the basis of the percentile between the values: 0.1%-24.9%\n",
    "\n",
    "for i in l:\n",
    "    if i >= 70:\n",
    "        print(i,25)\n",
    "        score.append(25)\n",
    "    elif i <=50:\n",
    "        print(i,0)\n",
    "        score.append(0)\n",
    "    elif i > 50 and i < 70:\n",
    "        s = (i-50/(70-50))*0.25\n",
    "        ss = (i-50)*1.25\n",
    "        print(i,s,ss)\n",
    "        score.append(ss)\n",
    "        \n",
    "        \n",
    "final['score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('dialogue_score.csv')\n",
    "bechdel = pd.read_csv('../Data/bechdel/all_movies_bechdel.csv')\n",
    "male = pd.read_csv('dialogue_score.csv')\n",
    "fin=pd.merge(bechdel,male, left_on='Title', right_on='movie_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise(row):  \n",
    "    if row['bechdel_rating'] == 0.0:\n",
    "        return 40\n",
    "    elif row['bechdel_rating'] == 1.0:\n",
    "        return 26.66\n",
    "    elif row['bechdel_rating'] == 2.0:\n",
    "        return 13.33\n",
    "    elif row['bechdel_rating'] == 3.0:\n",
    "        return 0\n",
    "    \n",
    "fin['bechdel_score'] = fin.apply(lambda row: categorise(row), axis=1)\n",
    "\n",
    "fin.to_csv('dialogue_bechdel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Final \"Gaze Score\"\n",
    "In this step we will be developing a mechanism in order to **assign a score to each film** within our scope. This scoring is important for us as we take into account all the factors analyzed above and assign a score from a **range of 0-100**.\n",
    "\n",
    "The divisiion of the score is as follows:\n",
    "1. **Bechdel Test** (max. 40%), score assigned based on the following criteria\n",
    "    1. If a movie passes **no rule**: 40%\n",
    "    2. If a movie passes **only the first rule**: 26.66%\n",
    "    3. If a movie passes **only the first and second rules**: 13.33%\n",
    "    4. If a movie passes **all rules**: 0%\n",
    "2. **Character description** (max. 35%), score assigned based on the following criteria\n",
    "    1. If a female character is described in a **highly sexist** manner: 35%\n",
    "    2. If a female character is described in a **dubious but problematic** manner: 17.5%\n",
    "    3. If a female character is not described in any of the above manners: 0%\n",
    "3. **Character dialogues** (max. 25%), score assigned based on the following criteria:\n",
    "    1. If a male character has less than or equal to 50% of the overrall dialogue in the script: 0%\n",
    "    2. If a male character has more than or equal to 70% of the overall dialogue in the script: 25%\n",
    "    3. If a male character has dialogue between 51% to 69% of the overall dialogue in the script: the percentage will be assigned on the basis of the percentile between values 0.1%-24.9%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****ahsan code for bechdel score here****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p>For assigning a score based on the type of character descriptions, we will be using the dataframe containing all the counts of body descriptions and dubious words for each film. We chose not to penalize films that contain just under the average amount of simple body descriptions, taking into consideration that film scripts will inadvertedly contain such descriptions.</p>\n",
    "\n",
    "<p> The following function assigns a score to each film according to its number of body occurences, and it more sensitive to the dubious values, if they are found.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>count</th>\n",
       "      <th>inappropriate_count</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>15.229007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spiderman</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>9.138681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Man of Steel</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>10.141361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001: A Space Odyssey</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beverly Hills Cop II</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4.378235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>17.295265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>5.261838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>8.519528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>The Bible</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                movie  count  \\\n",
       "0                                              Psycho     86   \n",
       "1                                           Spiderman     57   \n",
       "2                                        Man of Steel     70   \n",
       "3                               2001: A Space Odyssey      2   \n",
       "4                                Beverly Hills Cop II     11   \n",
       "..                                                ...    ...   \n",
       "75                         Terminator 2: Judgment Day    132   \n",
       "76          Star Wars: Episode I - The Phantom Menace      8   \n",
       "77  Pirates of the Caribbean: The Curse of the Bla...     60   \n",
       "78                                       Forrest Gump     20   \n",
       "79                                          The Bible      3   \n",
       "\n",
       "    inappropriate_count      score  \n",
       "0                     3  15.229007  \n",
       "1                     2   9.138681  \n",
       "2                     1  10.141361  \n",
       "3                     0   0.000000  \n",
       "4                     2   4.378235  \n",
       "..                  ...        ...  \n",
       "75                    0  17.295265  \n",
       "76                    0   0.000000  \n",
       "77                    0   5.261838  \n",
       "78                    6   8.519528  \n",
       "79                    0   0.000000  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vals = fem_desc_graph['count'].to_list()\n",
    "inapp_vals = fem_desc_graph['inappropriate_count'].to_list()\n",
    "\n",
    "# calculate the mean value of the sum of the values\n",
    "mean_val =  sum(vals)/len(vals) #average amount of body descriptions\n",
    "\n",
    "# calculate the percentile for the maximum value\n",
    "max_val = max(vals)\n",
    "max_percentile = 35 #our max value for the characters' description category\n",
    "\n",
    "# create a dictionary mapping each value to its percentile\n",
    "score = []\n",
    "\n",
    "for i, val in enumerate(vals):\n",
    "    if val < mean_val:\n",
    "        film_score = 0\n",
    "    else:\n",
    "        film_score = ((val-mean_val)/(max_val-mean_val))*30 + 1\n",
    "    if inapp_vals[i] > 0:\n",
    "        sigmoid_val = 1 / (1 + np.exp(-(inapp_vals[i] - 2.5) / 2))  # adjust the 2.5 parameter to adjust the sensitivity\n",
    "        inapp_score = sigmoid_val * 10\n",
    "        film_score += inapp_score\n",
    "    score.append(min(film_score, max_percentile))\n",
    "\n",
    "fem_desc_graph['score'] = score\n",
    "\n",
    "fem_desc_graph.drop(columns=['script_name'], inplace=True)\n",
    "fem_desc_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****ahsan code for final scores****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we proceed with creating a <b>final dataframe</b> containing all of the data retrieved from our scripts analysis and the movies' details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbid</th>\n",
       "      <th>Title</th>\n",
       "      <th>Decade</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Director</th>\n",
       "      <th>year</th>\n",
       "      <th>bechdel_rating</th>\n",
       "      <th>male_percen</th>\n",
       "      <th>nonmale_percentage</th>\n",
       "      <th>dialogue_score</th>\n",
       "      <th>bechdel_score</th>\n",
       "      <th>count</th>\n",
       "      <th>inappropriate_count</th>\n",
       "      <th>descriptions_score</th>\n",
       "      <th>gaze_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38969</td>\n",
       "      <td>Song of the South</td>\n",
       "      <td>40s</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Wilfred Jackson, Harve Foster</td>\n",
       "      <td>1946</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84.10</td>\n",
       "      <td>15.90</td>\n",
       "      <td>25.000</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41838</td>\n",
       "      <td>Samson and Delilah</td>\n",
       "      <td>40s</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Cecil B.DeMille</td>\n",
       "      <td>1949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31381</td>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>40s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Victor Fleming</td>\n",
       "      <td>1939</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.90</td>\n",
       "      <td>59.10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37536</td>\n",
       "      <td>The Bells of St. Mary</td>\n",
       "      <td>40s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Leo McCarey</td>\n",
       "      <td>1945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34167</td>\n",
       "      <td>Sergeant York</td>\n",
       "      <td>40s</td>\n",
       "      <td>War</td>\n",
       "      <td>Leo McCarey</td>\n",
       "      <td>1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>499549</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>2010s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>2009</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.06</td>\n",
       "      <td>31.94</td>\n",
       "      <td>22.575</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>10.440033</td>\n",
       "      <td>33.015033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>770828</td>\n",
       "      <td>Man of Steel</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Zack Snyder</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.76</td>\n",
       "      <td>23.24</td>\n",
       "      <td>25.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>10.138008</td>\n",
       "      <td>35.138008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3748528</td>\n",
       "      <td>Rogue One: A Star Wars Story</td>\n",
       "      <td>2010s</td>\n",
       "      <td>SCI-FI</td>\n",
       "      <td>Gareth Edwards</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.73</td>\n",
       "      <td>19.27</td>\n",
       "      <td>25.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1201607</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 2</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>David Yates</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.10</td>\n",
       "      <td>21.90</td>\n",
       "      <td>25.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>8.967871</td>\n",
       "      <td>33.967871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1877832</td>\n",
       "      <td>X-Men: Days of Future Past</td>\n",
       "      <td>2010s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Bryan Singer</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.21</td>\n",
       "      <td>23.79</td>\n",
       "      <td>25.000</td>\n",
       "      <td>26.66</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>6.460616</td>\n",
       "      <td>58.120616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdbid                                         Title Decade       Genre  \\\n",
       "0     38969                             Song of the South    40s   Animation   \n",
       "1     41838                            Samson and Delilah    40s  Historical   \n",
       "2     31381                            Gone with the Wind    40s       Drama   \n",
       "3     37536                         The Bells of St. Mary    40s     Musical   \n",
       "4     34167                                 Sergeant York    40s         War   \n",
       "..      ...                                           ...    ...         ...   \n",
       "76   499549                                        Avatar  2010s      SCI-FI   \n",
       "77   770828                                  Man of Steel  2010s      Action   \n",
       "78  3748528                  Rogue One: A Star Wars Story  2010s      SCI-FI   \n",
       "79  1201607  Harry Potter and the Deathly Hallows: Part 2  2010s     Fantasy   \n",
       "80  1877832                    X-Men: Days of Future Past  2010s      Action   \n",
       "\n",
       "                         Director  year  bechdel_rating  male_percen  \\\n",
       "0   Wilfred Jackson, Harve Foster  1946             2.0        84.10   \n",
       "1                 Cecil B.DeMille  1949             NaN          NaN   \n",
       "2                  Victor Fleming  1939             3.0        40.90   \n",
       "3                     Leo McCarey  1945             NaN          NaN   \n",
       "4                     Leo McCarey  1941             NaN          NaN   \n",
       "..                            ...   ...             ...          ...   \n",
       "76                  James Cameron  2009             3.0        68.06   \n",
       "77                    Zack Snyder  2013             3.0        76.76   \n",
       "78                 Gareth Edwards  2016             3.0        80.73   \n",
       "79                    David Yates  2011             3.0        78.10   \n",
       "80                   Bryan Singer  2014             1.0        76.21   \n",
       "\n",
       "    nonmale_percentage  dialogue_score  bechdel_score  count  \\\n",
       "0                15.90          25.000          13.33      1   \n",
       "1                  NaN             NaN            NaN      9   \n",
       "2                59.10           0.000           0.00     17   \n",
       "3                  NaN             NaN            NaN      4   \n",
       "4                  NaN             NaN            NaN      2   \n",
       "..                 ...             ...            ...    ...   \n",
       "76               31.94          22.575           0.00     91   \n",
       "77               23.24          25.000           0.00     70   \n",
       "78               19.27          25.000           0.00     12   \n",
       "79               21.90          25.000           0.00     56   \n",
       "80               23.79          25.000          26.66     48   \n",
       "\n",
       "    inappropriate_count  descriptions_score  gaze_score  \n",
       "0                     0            0.000000   38.330000  \n",
       "1                     0            0.000000    0.000000  \n",
       "2                     0            0.000000    0.000000  \n",
       "3                     0            0.000000    0.000000  \n",
       "4                     0            0.000000    0.000000  \n",
       "..                  ...                 ...         ...  \n",
       "76                    0           10.440033   33.015033  \n",
       "77                    1           10.138008   35.138008  \n",
       "78                    0            0.000000   25.000000  \n",
       "79                    2            8.967871   33.967871  \n",
       "80                    1            6.460616   58.120616  \n",
       "\n",
       "[80 rows x 15 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge final results to get the score\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path =\"/\".join(list(cwd.split('/')[0:-1])) \n",
    "\n",
    "df_bechdel_dialogue = pd.read_csv(path+ '/Data/Dialogue/dialogue_bechdel.csv')\n",
    "df_descriptions= pd.read_csv(path+ \"/Data/Descriptions/female_descriptions.csv\")\n",
    "\n",
    "final_scores = pd.merge(df_bechdel_dialogue,df_descriptions, left_on='Title',right_on=\"movie\",how='outer',indicator='_merge')\n",
    "\n",
    "final_scores = final_scores[['imdbid','Title','Decade','Genre','Director','year','bechdel_rating','male_percen',\n",
    "                            'nonmale_percentage','dialogue_score','bechdel_score','count','inappropriate_count','score','_merge']]\n",
    "final_scores.rename(columns={'score':'descriptions_score'},inplace=True)\n",
    "                    \n",
    "final_scores.drop_duplicates(inplace=True)\n",
    "                    \n",
    "final_scores\n",
    "\n",
    "scores_to_count = final_scores[['dialogue_score','bechdel_score','descriptions_score']]\n",
    "\n",
    "final_scores['gaze_score'] = scores_to_count.sum(axis=1)\n",
    "final_scores.drop_duplicates(subset=['Title'], inplace=True)\n",
    "final_scores.drop(columns=['_merge'], inplace=True)\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The camera: SPARQL metadata retrieval\n",
    "\n",
    "Finally, after gathering some preliminary results from the first analyses on film scripts and IMDB's reviews, we further deepened our research using [**Wikidata**](https://www.wikidata.org/wiki/Wikidata:Main_Page) and its **SPARQL endpoint**.\n",
    "\n",
    "While we had found another interesting database with a SPARQL endpoint, the [**Linked Internet Movie Database (IMDb)**](https://triplydb.com/Triply/linkedmdb), and proceeded with an initial phase of **data exploration** (as it was an unknown), we quickly found out that it was missing some of more relevant information for the scope of our project, such as the gender of people working on the movie (e.g. directors, writers...). Moreover, the \"imdb id\" it presented was actually different than the one on Wikidata, which, on the other hand, had all the necessary information.\n",
    "\n",
    "The SPARQL queries are based on the results coming from the [script analysis](###The-characters:-film-and-scripts-analysis) and [review analysis](##The-audience:-webscraping,-sentiment-and-sexism) (respectively, the \"characters\" and \"audience\" sections):,\n",
    "- The audience results,\n",
    "    - [FRA WRITE THE RESULTS HERE],\n",
    "- The characters results,\n",
    "    - Bechdel test: out of the 82 films what were evaluated:\n",
    "        - 38 films passed the Bechdel test\n",
    "        - 5 failed all rules\n",
    "        - 20 failed the second and third rule\n",
    "        - 9 failed the third rule\n",
    "    - Character dialogue analysis: [AHSAN WRITE SOMETHING HERE],\n",
    "    - Gaze score: [WRITE SOMETHING HERE]\n",
    "\n",
    "Queries:\n",
    "1. <span style=\"color:red;\">The \"audience\" query: *what audience is the most sexist?*, *Is there any decade in which the reviews are the most sexist?*</span>\n",
    "2. The \"characters\" queries:\n",
    "    1. Bechdel test: *how many of the [selected] films have **male** directors?*\n",
    "    2. Character dialogue: *what is the proportion between male and female writers in the [selected] films?*\n",
    "3. Gaze score queries:\n",
    "    1. *To what genre belong the top 10 films in the gaze score ranking?*\n",
    "    2. *Is there any correlation between rank in the gaze score ranking, box-office and production costs?*\n",
    "    3. <span style=\"color:red;\">*Is there any decade in which the films rank higher in the gaze score ranking?*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The \"Audience\" query: *what audience is the most sexist?*, *Is there any decade in which the reviews are the most sexist?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparql_dataframe\n",
    "\n",
    "wikidata_endpoint = 'https://query.wikidata.org/bigdata/namespace/wdq/sparql?query={SPARQL}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The \"Characters\" queries\n",
    "##### Bechdel test query: *how many of the [selected] films have **male** directors?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Characters dialogue query: *how many of the [selected] films have **male** directors?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaze score queries\n",
    "##### GS query 1: *To what genre belong the top 10 films in the gaze score ranking?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GS query 2: *Is there any correlation between rank in the gaze score ranking, box-office and production costs?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GS query 3: *Is there any decade in which the films rank higher in the gaze score ranking?*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
